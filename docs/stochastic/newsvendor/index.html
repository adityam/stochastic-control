<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Aditya Mahajan" />
  <meta name="title" content="ECSE 506: Stochastic Control and Decision Theory" />
  <title>ECSE 506: Stochastic Control and Decision Theory</title>
  
  <meta content="stochastic optimization" name="keywords" />
  

  <link rel="stylesheet" href="https://adityam.github.io/stochastic-control//css/style.css" type="text/css" /><script type="text/javascript"
    src="https://adityam.github.io/stochastic-control/js/mathjax-local.js" defer>
  </script>
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  <script type="module" defer
    src="//instant.page/3.0.0"
    integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1">
  </script>

  <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101261731);</script>
  <script async src="//static.getclicky.com/js"></script>

</head>
<body>
<div id="content">
<div class="title">
  <h1>ECSE 506: Stochastic Control and Decision Theory </h1>
  <h2><a href="http://www.cim.mcgill.ca/~adityam/">Aditya Mahajan</a> <br/>
      Winter 2022
  </h2>
  <h3><a href="https://adityam.github.io/stochastic-control/ ">About</a>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//lectures">Lectures</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//notes">Notes</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//coursework">Coursework</a>
</h3>
</div>



<div class="h1-title">Example: The Newsvendor Problem</div>

<figure>
<img src="/stochastic-control/banners/newsboy.jpg" title="To buy or not to buy" style="max-width:40em;" style="width:100.0%" alt="Image credit: https://americangallery.wordpress.com/category/cafferty-james-h/" /><figcaption aria-hidden="true">Image credit: https://americangallery.wordpress.com/category/cafferty-james-h/</figcaption>
</figure>
<p>TL;DR <em>The newsvendor problem is a simple model of stochastic optimization problem where a decision has to be made when there is uncertainty about the outcome. It also shows that for some stochastic optimization problems it is possible to obtain the qualitative properties of the nature of optimal solution.</em></p>
<hr />
<p>Each morning, a newsvendor has to decide how many newspapers to buy before knowing the demand during the day. The newsvendor purchases a newspaper at a cost of <span class="math inline">\(\$p\)</span> per newspaper and sells them at a cost of <span class="math inline">\(\$q\)</span> per newspaper, where <span class="math inline">\(q &gt; p\)</span>. Any unsold newspapers at the end of the day have no salvage value.</p>
<p>Let <span class="math inline">\(a\)</span> denote the number of newspapers bought and <span class="math inline">\(W\)</span> denotes the demand. If <span class="math inline">\(W &lt; a\)</span>, then the newsvendor will sell <span class="math inline">\(W\)</span> newspapers and receive a total earnings of <span class="math inline">\(q W - p a\)</span>. If <span class="math inline">\(W \ge a\)</span>, then the newsvendor will sell <span class="math inline">\(a\)</span> newspapers and receive a total earning of <span class="math inline">\(q a - p a\)</span>. Thus, the <em>reward</em> is <span class="math inline">\(r(a,W)\)</span>, where</p>
<p><span class="math display">\[r(a, w) = \begin{cases}
   q w - p a, &amp; \text{if } w &lt; a, \\
   q a - p a, &amp; \text{if } w \ge a. 
\end{cases} \]</span></p>
<p>An illustration of the reward function is shown below.</p>
<figure style="max-width:30em;">
<div id="observablehq-reward_plot-reward">

</div>
<div id="observablehq-viewof-p-reward">

</div>
<div id="observablehq-viewof-action-reward">

</div>
<figcaption>
<b>Figure 1</b><br/> Reward as a function of <span class="math inline">\(w\)</span> for a fixed value of <span class="math inline">\(a\)</span>. You can change the values of <span class="math inline">\(p\)</span> and <span class="math inline">\(a\)</span> by moving the sliders. Here <span class="math inline">\(q = 1\)</span>.
</figcaption>
</figure>
<script type="module">
import {Runtime, Inspector} from "https://cdn.jsdelivr.net/npm/@observablehq/runtime@4/dist/runtime.js";
import define from "https://api.observablehq.com/d/bf246f66927d3ddf.js?v=3";
new Runtime().module(define, name => {
  if (name === "reward_plot") return new Inspector(document.querySelector("#observablehq-reward_plot-reward"));
  if (name === "viewof p") return new Inspector(document.querySelector("#observablehq-viewof-p-reward"));
  if (name === "viewof action") return new Inspector(document.querySelector("#observablehq-viewof-action-reward"));
  return ["r","points","perf","plot","J","cost","plotJ","cost_values","a_opt","a"].includes(name);
});
</script>
<hr />
<p>The problem above has discrete action and discrete demand. To build intuition, we first consider the case where both the actions and demand are continuous. Let <span class="math inline">\(f(w)\)</span> denote the probability density of the demand and <span class="math inline">\(F(w)\)</span> denote the cumulative probability density. Then, the expected reward is <span class="math display">\[ \begin{equation} \label{eq:J}
J(a) = \int_{0}^a [ q w - p a ] f(w) dw + \int_{a}^\infty [ q a - p a ] f(w) dw. 
\end{equation}\]</span></p>
<p>As an illustration, the PDF of a particular distribution (see the plot later for exact choices of parameters) is shown below. Try to move the slider for <span class="math inline">\(a\)</span> to try and find an (approximately) optimal value of the action.</p>
<figure style="max-width:30em;">
<div id="observablehq-viewof-action">

</div>
<div id="observablehq-cost">

</div>
<div id="observablehq-perf">

</div>
<div id="observablehq-reward_plot">

</div>
<figcaption>
<b>Figure 2</b><br/> The value of expected cost as a function of action. In the first plot, the blue shaded region represents the probability of getting a demand less than the ordered goods and the red shared region represents the probability of getting a demand greater than the ordered goods. The second plot shows the reward function <span class="math inline">\(r(a,\cdot)\)</span>, which depends on the value of <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span>.
</figcaption>
</figure>
<p>We can also plot the performance as a function of action, and identify its maximma as shown in the plot below.</p>
<figure style="max-width:30em;">
<div id="observablehq-plotJ">

</div>
<figcaption>
<b>Figure 3</b><br/> The value of expected cost as a function of action. The blue dot shows the value of action chosen in Figure 2. The red dot shows the optimal value.
</figcaption>
</figure>
<p>The plot of <span class="math inline">\(J(a)\)</span> is concave. This suggests that we can use calculus to find the optimal value. In particular, to find the optimal action, we need to compute the <span class="math inline">\(a\)</span> such that <span class="math inline">\(dJ(a)/da = 0\)</span>. We first recall the Leibniz integral rule: <span class="math display">\[ \dfrac{d}{dx} \left( \int_{p(x)}^{q(x)} f(x,t) dt \right)
   = f(x, q(x)) \cdot \dfrac {d}{dx} q(x) 
   - f(x, p(x)) \cdot \dfrac {d}{dx} p(x) 
   + \int_{p(x)}^{q(x)} \dfrac{\partial}{\partial x} f(x,t) dt.
\]</span></p>
<p>Thus, the derivative of the first term of \eqref{eq:J} is <span class="math display">\[ [q a - p a ] f(a) + \int_{0}^a [ -p ] f(w) dw 
 = [q a - p a ] f(a) - p F(a).
\]</span></p>
<p>Similarly, the derivative of the second term of \eqref{eq:J} is <span class="math display">\[ - [q a - p a] f(a) + \int_{a}^{\infty} (q-p)f(w)dw 
 = - [q a - p a] f(a) + (q -p)[ 1 - F(a)].
\]</span></p>
<p>Combining the two, we get that <span class="math display">\[ \dfrac{dJ(a)}{da} = - p F(a) + (q - p) [ 1 - F(a) ]. \]</span></p>
<p>Equating this to <span class="math inline">\(0\)</span>, we get <span class="math display">\[ F(a) = \dfrac{ q - p }{ q}
\quad\text{or}\quad
a = F^{-1} \left( \dfrac{ q - p }{ q } \right).
\]</span> In the literature, the quantity <span class="math inline">\((q-p)/q\)</span> is called the <em>critical fractile</em>.</p>
<p>An illustration of the optimal decision rule is shown below.</p>
<figure style="max-width:30em;">
<div id="observablehq-viewof-p">

</div>
<div id="observablehq-a">

</div>
<div id="observablehq-plot">

</div>
<figcaption>
<b>Figure 4</b><br/>The value of optimal action for different values of <span class="math inline">\(p\)</span>. The optimal action is such that the area of the red shaded region in the curve equals the critical factile value <span class="math inline">\((q - p)/q\)</span>. <br /> In this example, it is assumed that <span class="math inline">\(W\)</span> is distributed according to <a
href="https://en.wikipedia.org/wiki/Kumaraswamy_distribution">Kumaraswamy distribution</a> with parameters <span class="math inline">\((a,b) = (2,5)\)</span> and support <span class="math inline">\([0,100]\)</span>. The value of <span class="math inline">\(q=1\)</span>.
</figcaption>
</figure>
<script type="module">
import {Runtime, Inspector} from "https://cdn.jsdelivr.net/npm/@observablehq/runtime@4/dist/runtime.js";
import define from "https://api.observablehq.com/d/49e833a074ec7152.js?v=3";
new Runtime().module(define, name => {
  if (name === "perf") return new Inspector(document.querySelector("#observablehq-perf"));
  if (name === "viewof p") return new Inspector(document.querySelector("#observablehq-viewof-p"));
  if (name === "reward_plot") return new Inspector(document.querySelector("#observablehq-reward_plot"));
  if (name === "viewof action") return new Inspector(document.querySelector("#observablehq-viewof-action"));
  if (name === "plot") return new Inspector(document.querySelector("#observablehq-plot"));
  if (name === "plotJ") return new Inspector(document.querySelector("#observablehq-plotJ"));
  if (name === "a") return new Inspector(document.querySelector("#observablehq-a"));
  if (name === "cost") return new Inspector(document.querySelector("#observablehq-cost"));
  return ["r","points","J","cost_values","a_opt"].includes(name);
});
</script>
<dl>
<dt>Remark</dt>
<dd><p>Strictly speaking, we also need to verify that the function <span class="math inline">\(J(a)\)</span> is concave. To do so, we compute the second derivative: <span class="math display">\[
  \frac{d^2 J(a)}{da^2} = - p f(a) - (q - p) f(a) = -q f(a) \le 0.
\]</span> Hence, the <span class="math inline">\(J(a)\)</span> is concave and the extremum value computed above is a maximum.</p>
</dd>
</dl>
<hr />
<p>Now, we come back to the problem with discrete actions and discrete demand. Suppose <span class="math inline">\(W\)</span> takes the values <span class="math inline">\(\ALPHABET W = \{ w_1, w_2, \dots, w_k \}\)</span> (where <span class="math inline">\(w_1 &lt; w_2 &lt; \cdots &lt; w_k\)</span>) with probabilities <span class="math inline">\(\{ μ_1, μ_2, \dots, μ_k \}\)</span>. It is ease to see that in this case the action <span class="math inline">\(a\)</span> should be in the set <span class="math inline">\(\{ w_1, w_2, \dots, w_k \}\)</span>.</p>
<p>As an illustration, consider the case when <span class="math inline">\(\ALPHABET W = \{0, 1, \dots, 100\}\)</span>.</p>
<figure style="max-width:30em;">
<div id="observablehq-viewof-p--discrete">

</div>
<div id="observablehq-viewof-action--discrete">

</div>
<div id="observablehq-cost--discrete">

</div>
<div id="observablehq-perf--discrete">

</div>
<div id="observablehq-reward_plot--discrete">

</div>
<figcaption>
<b>Figure 5</b><br/> The value of expected cost as a function of action. This is similar to Figure 1, except that demand and actions can take discrete values.
</figcaption>
</figure>
<script type="module">
import {Runtime, Inspector} from "https://cdn.jsdelivr.net/npm/@observablehq/runtime@4/dist/runtime.js";
import define from "https://api.observablehq.com/d/86f25914f7dddb7f.js?v=3";
new Runtime().module(define, name => {
  if (name === "perf") return new Inspector(document.querySelector("#observablehq-perf--discrete"));
  if (name === "cost") return new Inspector(document.querySelector("#observablehq-cost--discrete"));
  if (name === "reward_plot") return new Inspector(document.querySelector("#observablehq-reward_plot--discrete"));
  if (name === "viewof p") return new Inspector(document.querySelector("#observablehq-viewof-p--discrete"));
  if (name === "viewof action") return new Inspector(document.querySelector("#observablehq-viewof-action--discrete"));
  return ["r","points","plot","J","plotJ","cost_values","a_opt","a"].includes(name);
});
</script>
<p>In the discrete case, the brute force search is easier (because there are a finite rather than continuous number of values). We cannot directly use the ideas from calculus because functions over discrete domain are not differentiable. But we can use a very similar idea. Instead of checking if <span class="math inline">\(dJ(a)/da = 0\)</span>, we check the sign of <span class="math inline">\(J(w_{i+1}) - J(w_i)\)</span>.</p>
<p>The expected reward for choice <span class="math inline">\(w_i\)</span> is <span class="math display">\[ \begin{align*} J(w_i) &amp;=
\sum_{j &lt; i} μ_j [ q w_j - p w_i ] + \sum_{j \ge i} μ_j [q w_i - p w_i]
\\
&amp;= -p w_i + q \Bigl[ \sum_{j &lt; i}  μ_j w_j + \sum_{j \ge i} μ_j w_i \Bigr].
\end{align*}\]</span></p>
<p>Thus, <span class="math display">\[ \begin{align*}
  J(w_{i+1}) - J(w_i) &amp;= 
  -p w_{i+1} + q \Bigl[ \sum_{j &lt; i+1}  μ_j w_j + \sum_{j \ge i+1} μ_j w_{i+1} \Bigr]
  \\
  &amp;\quad + p w_i - q \Bigl[ \sum_{j &lt; i}  μ_j w_j + \sum_{j \ge i} μ_j w_i \Bigr]
  \\
  &amp;= -p (w_{i+1} - w_i) + q \Bigl[ \sum_{j \ge i + 1} μ_j ( w_{i+1} - w_i) \Bigr] 
  \\
  &amp;= \big( - p + q [ 1 - M_i ] \big) (w_{i+1} - w_i),
\end{align*}\]</span> where <span class="math inline">\(M_i\)</span> is the cumulative probability mass function. Note that <span class="math display">\[ 
M_i \le \dfrac{q-p}{q}
\iff
-p + q [ 1 - M_i ] \ge 0.
\]</span> Thus, for all <span class="math inline">\(i\)</span> such that <span class="math inline">\(M_i \le (q-p)/q\)</span>, <span class="math inline">\(J(w_{i+1}) \ge J(w_i)\)</span>. On the other hand, for all <span class="math inline">\(i\)</span> such that <span class="math inline">\(M_i &gt; (q-p)/q)\)</span>, <span class="math inline">\(J(w_{i+1}) &lt; J(w_i)\)</span>. Thus, the optimal amount to order is the largest <span class="math inline">\(w_i\)</span> such that <span class="math inline">\(M_i \le (q-p)/q\)</span>.</p>
<p>Note that the structure of the optimal solution is the same for continuous and discrete demand distributions.</p>
<h1 class="unnumbered" id="exercises">Exercises</h1>
<ol type="1">
<li><p><strong>Qualitative properties of optimal solution.</strong> The numerical results shown in Figure 4 suggest that, for a fixed value of <span class="math inline">\(q\)</span>, the optimal value of <span class="math inline">\(a\)</span> is a decreasing function of <span class="math inline">\(p\)</span>. Intuitively, this makes sense: if the purchase price of the newspaper increases, but the selling price remains the same, then the newsvendor should buy less newspapers. Formally prove this statement.</p>
<p><em>Hint</em>: The CDF of a distribution is a weakly increasing function.</p></li>
<li><p><strong>Monotonicity of optimal action.</strong> Consider two scenarios for the case with continuous demand and actions. In scenario 1, the demand is distributed according to PDF <span class="math inline">\(f_1\)</span>. In scenario 2, it is distributed according to PDF <span class="math inline">\(f_2\)</span>. Suppose <span class="math inline">\(F_1(w) \le F_2(w)\)</span> for all <span class="math inline">\(w\)</span>. Show that the optimal action <span class="math inline">\(a_1\)</span> for scenario 1 is greater than the optimal action <span class="math inline">\(a_2\)</span> for scenario 2.</p>
<p><em>Hint</em>: Plot the two CDFs and try to interpret the optimal decision rule graphically.</p></li>
<li><p><strong>Selling random wind.</strong> The amount <span class="math inline">\(W\)</span> of power generated by the wind turbine is a positive real-valued random variable with probability density function <span class="math inline">\(f\)</span>. The operator of the wind turbine has to commit to provide a certain amount of power in the day-ahead market. The price of power is <span class="math inline">\(\$p\)</span> per MW.</p>
<p>If the operator commits to provide <span class="math inline">\(a\)</span> MW of power and the wind generation <span class="math inline">\(W\)</span> is less than <span class="math inline">\(a\)</span>, then he has to buy the balance <span class="math inline">\(a - W\)</span> from a reserves market at the cost of <span class="math inline">\(\$ q\)</span> per unit, where <span class="math inline">\(q &gt; p\)</span>. Thus, the reward of the operator is <span class="math inline">\(r(a,W)\)</span> where <span class="math display">\[ r(a, w) = \begin{cases}
   p a, &amp; \text{if } w &gt; a \\
   p a - q (a  - w), &amp; \text{if } w &lt; a.
\end{cases}\]</span></p>
<p>Find the value of commitment <span class="math inline">\(a\)</span> that maximizes the expected reward.</p></li>
</ol>
<h1 class="unnumbered" id="references">References</h1>
<p>Perhaps the earliest model of the newsvendor problem appeared in <span class="citation" data-cites="Edgeworth1888">Edgeworth (<a href="#ref-Edgeworth1888" role="doc-biblioref">1888</a>)</span> in the context of a bank setting the level of cash reserves to cover demands from its customers. The solution to the basic model presented above and some of its variants was provided in <span class="citation" data-cites="Morse1951">Morse and Kimball (<a href="#ref-Morse1951" role="doc-biblioref">1951</a>)</span>; <span class="citation" data-cites="Arrow1951">Arrow et al. (<a href="#ref-Arrow1951" role="doc-biblioref">1952</a>)</span>; <span class="citation" data-cites="Whitin1953">Whitin (<a href="#ref-Whitin1953" role="doc-biblioref">1953</a>)</span>. See <span class="citation" data-cites="Porteus2008">Porteus (<a href="#ref-Porteus2008" role="doc-biblioref">2008</a>)</span> for an accessible introduction.</p>
<p>The property <span class="math inline">\(F_1(w) \le F_2(w)\)</span> used in Exercise 2 is called <a href="../../mdp/stochastic-dominance">stochastic dominance</a>. Later in the course, we will study how stochastic dominance is useful to establish <a href="../../mdp/monotonicity">monotonicity properties of general MDPs</a>.</p>
<p>The example of selling random wind in Exercise 3 is taken from <span class="citation" data-cites="Bitar2012">Bitar et al. (<a href="#ref-Bitar2012" role="doc-biblioref">2012</a>)</span>.</p>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Arrow1951" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Arrow, K.J., Harris, T., and Marschak, J.</span> 1952. Optimal inventory policy. <em>Econometrica</em> <em>20</em>, 1, 250–272. DOI: <a href="https://doi.org/10.2307/1907830">10.2307/1907830</a>.
</div>
<div id="ref-Bitar2012" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Bitar, E., Poolla, K., Khargonekar, P., Rajagopal, R., Varaiya, P., and Wu, F.</span> 2012. Selling random wind. <em>2012 45th hawaii international conference on system sciences</em>, IEEE, 1931–1937.
</div>
<div id="ref-Edgeworth1888" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Edgeworth, F.Y.</span> 1888. The mathematical theory of banking. <em>Journal of the Royal Statistical Society</em> <em>51</em>, 1, 113–127. Available at: <a href="https://www.jstor.org/stable/2979084">https://www.jstor.org/stable/2979084</a>.
</div>
<div id="ref-Morse1951" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Morse, P. and Kimball, G.</span> 1951. <em>Methods of operations research</em>. Technology Press of MIT.
</div>
<div id="ref-Porteus2008" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Porteus, E.L.</span> 2008. Building intuition: Insights from basic operations management models and principles. In: D. Chhajed and T.J. Lowe, eds., Springer, 115–134. DOI: <a href="https://doi.org/10.1007/978-0-387-73699-0">10.1007/978-0-387-73699-0</a>.
</div>
<div id="ref-Whitin1953" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Whitin, S.</span> 1953. <em>The theory of inventory management</em>. Princeton University Press.
</div>
</div>


<p class="categories">
This entry 

 was last updated on 11 Jan 2022
 and posted in 

<a href="https://adityam.github.io/stochastic-control/categories/stochastics">
  Stochastics</a>
and tagged
<a href="https://adityam.github.io/stochastic-control/tags/stochastic-optimization">stochastic optimization</a>.</p>



    </div>
  </body>
</html>


