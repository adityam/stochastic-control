<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>stochastic optimization on ECSE 506: Stochastic Control and Decision Theory</title>
    <link>https://adityam.github.io/stochastic-control/tags/stochastic-optimization/</link>
    <description>Recent content in stochastic optimization on ECSE 506: Stochastic Control and Decision Theory</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://adityam.github.io/stochastic-control/tags/stochastic-optimization/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Prelim: Risk Sensitive Utility</title>
      <link>https://adityam.github.io/stochastic-control/risk-sensitive/risk-sensitive-utility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/risk-sensitive/risk-sensitive-utility/</guid>
      <description>Risk sensitivity is relative to the idea of utility. The value of a sum of money \(z\) to a decision maker may not be proportional to \(z\) itself but may be some general increasing function \(\mathsf{U}(z)\), known as the utility function. For example, in the example on optimal gambling considered earlier, we had assumed that the utility for wealth \(z\) is \(\log z\). If a decision maker has utility function \(\mathsf{U}\), then the value of a random outcome \(Z\) will be defined by the expected utility \(\EXP[\mathsf{U}(Z)]\).</description>
    </item>
    
    <item>
      <title>Prelim: Stochastic optimization</title>
      <link>https://adityam.github.io/stochastic-control/stochastic/stochastic-optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/stochastic/stochastic-optimization/</guid>
      <description>Let’s start with the simplest optimization problem. A decision maker has to choose an action \(a \in \ALPHABET A\). Upon choosing the action \(a\), the decision maker incurs a cost \(c(a)\). What action should the decision maker pick to minimize the cost?
Formally, the above optimization problem may be written as \[ \begin{equation} \label{eq:basic} \min_{a \in \ALPHABET A} c(a). \end{equation}\]
When the action space \(\ALPHABET A\) is finite, say \(\ALPHABET A = \{1, \dots, m\}\), solving the optimization problem \eqref{eq:basic} is conceptually straight-forward: enumerate the cost of all possible actions, i.</description>
    </item>
    
    <item>
      <title>Example: Inventory Management (revisited)</title>
      <link>https://adityam.github.io/stochastic-control/inf-mdp/inventory-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/inf-mdp/inventory-management/</guid>
      <description>TL;DR One of the potential benefits of modeling a system as infinite horizon discounted cost MDP is that it can be simpler to identify an optimal policy. We illustrate this using the inventory management example.
Consider the model for inventory management and assume that it runs for an infinite horizon. We assume that the per-step cost is given by \[c(s,a,s_{+}) = p a + γ h(s), \] where \[ h(s) = \begin{cases} c_h s, &amp;amp; \text{if $s \ge 0$} \\ -c_s s, &amp;amp; \text{if $s &amp;lt; 0$}, \end{cases}\] where \(a\) is the per-unit holding cost, \(b\) is the per-unit shortage cost, and \(p\) is the per-unit procurement cost.</description>
    </item>
    
    <item>
      <title>Example: The Newsvendor Problem</title>
      <link>https://adityam.github.io/stochastic-control/stochastic/newsvendor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/stochastic/newsvendor/</guid>
      <description>Image credit: https://americangallery.wordpress.com/category/cafferty-james-h/ TL;DR The newsvendor problem is a simple model of stochastic optimization problem where a decision has to be made when there is uncertainty about the outcome. It also shows that for some stochastic optimization problems it is possible to obtain the qualitative properties of the nature of optimal solution.
Each morning, a newsvendor has to decide how many newspapers to buy before knowing the demand during the day.</description>
    </item>
    
    <item>
      <title>Assignment 1</title>
      <link>https://adityam.github.io/stochastic-control/assignments/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/assignments/01/</guid>
      <description>Exercise 1 from the notes on stochastic optimization. Write a computer program in any language of your choice to find the optimal policy. You must submit your code along with your solution.
Exercise 2 from the notes on stochastic optimization. Write a computer program in any language of your choice to find the optimal policy. You must submit your code along with your solution.
Exercise 3 from the notes on the newsvendor problem.</description>
    </item>
    
  </channel>
</rss>
