<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aditya Mahajan">
<meta name="dcterms.date" content="2024-01-28">
<meta name="keywords" content="MDPs, Markov policies, dynamic programming, comparison principle, principle of irrelevant information">
<meta name="description" content="ECES 506 (Stochastic Control and Decision Theory)">

<title>Course Notes - 5&nbsp; Finite horizon MDPs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../mdps/gambling.html" rel="next">
<link href="../stochastic-optimization/interchange.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/nutshell-1.0.6/nutshell.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script>
// https://github.com/mathjax/MathJax/issues/2744#issuecomment-1658624747
// To fix the bug that uppercase unicode letters are shown in italic
window.MathJax = {
  startup: {
    ready() {
      const {RANGES} = MathJax._.core.MmlTree.OperatorDictionary;
      const {TEXCLASS} = MathJax._.core.MmlTree.MmlNode;
      RANGES.splice(4, 1,
        [0x0370, 0x0385, TEXCLASS.ORD, 'mi'],
        [0x0386, 0x3AB, TEXCLASS.ORD, 'mi', 'normal'],
        [0x03AC, 0x1A20, TEXCLASS.ORD, 'mi']
      );
      MathJax.startup.defaultReady();
    }
  },
  tex: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    tags: "ams",
    macros: {
      PR: "\\mathbb{P}",
      EXP: "\\mathbb{E}",
      IND: "\\mathbb{I}",
      ONES: "\\mathbb{1}",
      reals: "\\mathbb{R}",
      integers: "\\mathbb{Z}",
      BLANK: "\\mathfrak{E}",
      TRANS: "\\intercal",
      BELLMAN: "\\mathcal{B}",
      RICCATI: "\\mathcal{R}",
      GAIN: "\\mathcal{G}",
      GREEDY: "\\mathcal{G}",
      MISMATCH: "\\mathcal{D}",
      VEC: "\\operatorname{vec}",
      diag: "\\operatorname{diag}",
      ROWS: "\\operatorname{vec}",
      TR: "\\operatorname{Tr}",   
      SPAN: "\\operatorname{sp}",   
      DRE: "\\operatorname{DRE}",   
      DARE: "\\operatorname{DARE}",   
      LQR: "\\operatorname{LQR}",   
      ALPHABET: ["\\mathcal{#1}", 1],
      MATRIX: ["\\begin{bmatrix} #1 \\end{bmatrix}", 1],
      NORM: ["\\left\\lVert \\mathstrut #1 \\right\\rVert", 1],
      ABS: ["\\left\\lvert \\mathstrut #1 \\right\\rvert", 1],
      GRAD: "\\nabla"
    },
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
};
</script>
<script async="" data-id="101261731" src="//static.getclicky.com/js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../stochastic-control/index.html"> 
<span class="menu-text">Stochastic Control</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/adityam/stochastic-control" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../mdps/intro.html">MDPs</a></li><li class="breadcrumb-item"><a href="../mdps/intro.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Finite horizon MDPs</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the course</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Stochastic Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/newsvendor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The newsvendor problem</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/certainty-equivalence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Certainty equivalence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../stochastic-optimization/interchange.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Interchange arguments</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">MDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Finite horizon MDPs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/gambling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Optimal gambling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Inventory Management</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/monotone-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Monotonicity of value function and optimal policies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/power-delay-tradeoff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Power-delay tradeoff in wireless communication</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/reward-shaping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Reward Shaping</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/optimal-stopping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Optimal stopping</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inf-horizon.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Infinite horizon MDPs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mdp-algorithms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">MDP algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/inventory-management-revisited.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Inventory management (revisted)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/mobile-edge-computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Service Migration in Mobile edge computing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/computational-complexity-vi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Computational complexity of value interation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/martingale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Thirfty and equalizing policies</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/linear-programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Linear programming formulation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/lipschitz-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Lipschitz MDPs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../mdps/periodic-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Periodic MDPs</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">POMDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pomdps/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pomdps/sequential-hypothesis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Sequential hypothesis testing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Approx DP</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/approx-DP.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Approximate dynamic programming</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/policy-loss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Upper bounds on policy loss</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../approx-mdps/model-approximation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Model approximation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Risk sensitive MDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../risk-sensitive/risk-sensitive-utility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Risk Sensitive Utility</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../risk-sensitive/risk-sensitive-mdps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Risk Sensitive MDPs</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Linear systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-systems/lqr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Linear quadratic regulation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-systems/large-scale-systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Large scale systems</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">RL</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../rl/stochastic-approximation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Stochastic approximation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Dec-POMDPs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../dec-pomdps/designers-approach.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Designer’s Approach</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">Probability Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/convergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Convergence of random variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/sub-gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Sub-Gaussian random variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/change-of-measure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Change of Measure</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/IPM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Integral Probablity Metrics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/markov-chains.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Markov chains</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/martingales.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Martingales</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../probability/stochastic-stability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Stochastic stability</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true">
 <span class="menu-text">Linear Algebra Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/matrix-relationships.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Some useful matrix relationships</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/positive-definite-matrix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Positive definite matrices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/svd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Singular value decomposition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../linear-algebra/rkhs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Reproducing Kernel Hilbert Space</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="true">
 <span class="menu-text">Convexity Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../convexity/convexity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Convex sets and convex functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../convexity/duality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Duality</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" aria-expanded="true">
 <span class="menu-text">Assignments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../assignments/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assignment 2</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#an-example" id="toc-an-example" class="nav-link active" data-scroll-target="#an-example"><span class="header-section-number">5.1</span> An example</a></li>
  <li><a href="#basic-model-and-structure-of-optimal-policies" id="toc-basic-model-and-structure-of-optimal-policies" class="nav-link" data-scroll-target="#basic-model-and-structure-of-optimal-policies"><span class="header-section-number">5.2</span> Basic model and structure of optimal policies</a></li>
  <li><a href="#performance" id="toc-performance" class="nav-link" data-scroll-target="#performance"><span class="header-section-number">5.3</span> Performance of Markov policies</a>
  <ul class="collapse">
  <li><a href="#exm-peak-control-continued" id="toc-exm-peak-control-continued" class="nav-link" data-scroll-target="#exm-peak-control-continued"><span class="header-section-number">5.3.1</span> Example&nbsp;<span>5.1</span> (continued)</a></li>
  </ul></li>
  <li><a href="#DP" id="toc-DP" class="nav-link" data-scroll-target="#DP"><span class="header-section-number">5.4</span> Dynamic Programming Decomposition</a>
  <ul class="collapse">
  <li><a href="#exm-peak-control-continued-1" id="toc-exm-peak-control-continued-1" class="nav-link" data-scroll-target="#exm-peak-control-continued-1"><span class="header-section-number">5.4.1</span> Example&nbsp;<span>5.1</span> (continued)</a></li>
  <li><a href="#back-to-the-proof" id="toc-back-to-the-proof" class="nav-link" data-scroll-target="#back-to-the-proof"><span class="header-section-number">5.4.2</span> Back to the proof</a></li>
  </ul></li>
  <li><a href="#more-examples" id="toc-more-examples" class="nav-link" data-scroll-target="#more-examples"><span class="header-section-number">5.5</span> More examples</a>
  <ul class="collapse">
  <li><a href="#machine-replacement" id="toc-machine-replacement" class="nav-link" data-scroll-target="#machine-replacement"><span class="header-section-number">5.5.1</span> Machine replacement</a></li>
  </ul></li>
  <li><a href="#variations-of-a-theme" id="toc-variations-of-a-theme" class="nav-link" data-scroll-target="#variations-of-a-theme"><span class="header-section-number">5.6</span> Variations of a theme</a>
  <ul class="collapse">
  <li><a href="#sec-cost-depending-on-next-state" id="toc-sec-cost-depending-on-next-state" class="nav-link" data-scroll-target="#sec-cost-depending-on-next-state"><span class="header-section-number">5.6.1</span> Cost depends on next state</a></li>
  <li><a href="#discounted-cost" id="toc-discounted-cost" class="nav-link" data-scroll-target="#discounted-cost"><span class="header-section-number">5.6.2</span> Discounted cost</a></li>
  <li><a href="#multiplicative-cost" id="toc-multiplicative-cost" class="nav-link" data-scroll-target="#multiplicative-cost"><span class="header-section-number">5.6.3</span> Multiplicative cost</a></li>
  <li><a href="#exponential-cost" id="toc-exponential-cost" class="nav-link" data-scroll-target="#exponential-cost"><span class="header-section-number">5.6.4</span> Exponential cost function</a></li>
  <li><a href="#optimal-stopping" id="toc-optimal-stopping" class="nav-link" data-scroll-target="#optimal-stopping"><span class="header-section-number">5.6.5</span> Optimal stopping</a></li>
  <li><a href="#minimax-setup" id="toc-minimax-setup" class="nav-link" data-scroll-target="#minimax-setup"><span class="header-section-number">5.6.6</span> Minimax setup</a></li>
  </ul></li>
  <li><a href="#sec-mdp-cts-spaces" id="toc-sec-mdp-cts-spaces" class="nav-link" data-scroll-target="#sec-mdp-cts-spaces"><span class="header-section-number">5.7</span> Continuous state and action spaces</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  <li><a href="#notes" id="toc-notes" class="nav-link" data-scroll-target="#notes">Notes</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/adityam/stochastic-control/edit/quarto/mdps/intro.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../mdps/intro.html">MDPs</a></li><li class="breadcrumb-item"><a href="../mdps/intro.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Finite horizon MDPs</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Finite horizon MDPs</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="http://www.cim.mcgill.ca/~adityam">Aditya Mahajan</a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="http://www.mcgill.ca/ece">
            McGill University
            </a>
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Updated</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 28, 2024</p>
    </div>
  </div>
  
    
  </div>
  

<div>
  <div class="keywords">
    <div class="block-title">Keywords</div>
    <p>MDPs, Markov policies, dynamic programming, comparison principle, principle of irrelevant information</p>
  </div>
</div>

</header>


<section id="an-example" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="an-example"><span class="header-section-number">5.1</span> An example</h2>
<p>To fix ideas, we start with an example.</p>
<div id="exm-peak-control" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.1</strong></span> Consider a <em>controlled</em> Markov chain defined over <span class="math inline">\(\ALPHABET S = \{-2, -1, 0, 1, 2\}\)</span> with two control actions, i.e., <span class="math inline">\(\ALPHABET A = \{0, 1\}\)</span>. If action <span class="math inline">\(A = 0\)</span> is chosen, the chain evolves according to its “natural” dynamics, which are shown below:</p>
<div id="fig-peak1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-peak1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/peak-control1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-peak1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.1: “Natural” dynamics of the Markov chain
</figcaption>
</figure>
</div>
<p>When action <span class="math inline">\(A = 1\)</span> is chosen, the chain evolves according to the “forced” dynamics, which are shown below:</p>
<div id="fig-peak2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-peak2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/peak-control2.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-peak2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.2: “Forced” dynamics of the Markov chain
</figcaption>
</figure>
</div>
<p>Note that under the natural dynamics, the Markov chain will settle to a uniform steady-state distribution; under the forced dynamics, the Markov chain settle to a distribution which is unimodal with a peak at state <span class="math inline">\(0\)</span>.</p>
<p>Suppose it is desirable to keep the Markov chain close to state <span class="math inline">\(0\)</span>. We capture this by the system incurs a <em>running cost</em> equal to <span class="math inline">\(s^2\)</span> in state <span class="math inline">\(s\)</span>. In addition, choosing action <span class="math inline">\(A=0\)</span> is free but choosing action <span class="math inline">\(A=1\)</span> has a <em>correction cost</em> <span class="math inline">\(p\)</span>.</p>
<p>Thus, the decision maker is in a conundrum. It may allow the system to follow its natural dynamics, which causes the system to reach states with larger absolute value and incur a running cost <span class="math inline">\(s^2\)</span>; or it may decide to force the system to drift towards state <span class="math inline">\(0\)</span>, which reduces the running cost but, in turn, incurs a correction cost <span class="math inline">\(p\)</span>. How should the decision maker choose its actions?</p>
</div>
</section>
<section id="basic-model-and-structure-of-optimal-policies" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="basic-model-and-structure-of-optimal-policies"><span class="header-section-number">5.2</span> Basic model and structure of optimal policies</h2>
<p>The type of model described above is called Markov decision processes (MDP), and they are the simplest model of a stochastic control system. There are two ways to model MDPs, which we describe below.</p>
<p>The first method to model MDPs is to think of them as a <strong>controlled</strong> Markov process; in particular, an MDP is a stochastic process <span class="math inline">\(\{S_t\}_{t \ge 1}\)</span>, <span class="math inline">\(S_t \in \ALPHABET S\)</span>, <em>controlled</em> by the process <span class="math inline">\(\{A_t\}_{t \ge 1}\)</span>, <span class="math inline">\(A_t \in \ALPHABET A\)</span>, which satisfies the <strong>controlled Markov property</strong>: <span class="math display">\[
  \PR(S_{t+1} = s_{t+1} \mid S_{1:t} = s_{1:t}, A_{1:t} = a_{1:t})
  =
  \PR(S_{t+1} = s_{t+1} \mid S_t = s_t, A_t = a_t).
\]</span> For models with finite state and action spaces, the right-hand side of the above may be viewed as an element of the <strong>controlled transition matrix</strong> <span class="math inline">\(P_t(a_t)\)</span>. For instnace, in the example described at the beginning of this section, we have <span class="math display">\[
\def\1{\tfrac 12}
P(0) = \MATRIX{ \1&amp; \1&amp;  0&amp;  0&amp;  0\\
                \1&amp; 0 &amp; \1&amp;  0&amp;  0\\
                0&amp;  \1&amp;  0&amp;  \1&amp; 0\\
                0&amp;  0&amp;  \1&amp;   0&amp; \1 \\
                0&amp;  0&amp;   0&amp;  \1&amp; \1}
\quad\text{and}\quad
\def\1{\tfrac 14}
\def\2{\tfrac 34}
\def\3{\tfrac 12}
P(1) = \MATRIX{ \1&amp; \2&amp;  0&amp;  0&amp;  0\\
                \1&amp; 0 &amp; \2&amp;  0&amp;  0\\
                0&amp;  \1&amp; \3&amp;  \1&amp; 0\\
                0&amp;  0&amp;  \2&amp;   0&amp; \1 \\
                0&amp;  0&amp;   0&amp;  \2&amp; \1}
\]</span> Since the model is time-homogeneous, we have replaced <span class="math inline">\(P_t(a)\)</span> by just <span class="math inline">\(P(a)\)</span>.</p>
<p>This representation is compact and convenient for computational purposes, but I personally feel that it can be a bit opaque for proving the fundamental results of MDP theory. For that reason, I prefer to start with the second representation, which is desibed below.</p>
<p>In the second representation, the dynamic behavior of an MDP is modeled by an equation <span class="math display">\[ \begin{equation}
  S_{t+1} = f_t(S_t, A_t, W_t) \label{eq:state}
\end{equation}\]</span> where <span class="math inline">\(S_t \in \ALPHABET S\)</span> is the state, <span class="math inline">\(A_t \in \ALPHABET A\)</span> is the control input, and <span class="math inline">\(W_t \in \ALPHABET W\)</span> is the noise. An agent/controller observes the state and chooses the control input <span class="math inline">\(A_t\)</span>.</p>
<p>We call this the <strong>functional representation</strong> of the MDP. Eq.&nbsp;\eqref{eq:state} is a <em>non-linear</em> <em>stochastic</em> state-space model—<em>non-linear</em> because <span class="math inline">\(f_t\)</span> can be any nonlinear function; <em>stochastic</em> because the system is driven by stochastic noise <span class="math inline">\(\{W_t\}_{t \ge 1}\)</span>.</p>
<p>Note that the controlled Markov chain representation can be easily translated to a functional representation by taking <span class="math inline">\(W_t\)</span> to be a uniform <span class="math inline">\([0,1]\)</span> random variable and using a differnet <a href="https://en.wikipedia.org/wiki/Inverse_transform_sampling">:Smirnov transformation</a> for each state action pair <span class="math inline">\((S_t, A_t)\)</span>.</p>
<p>At each time, the system incurs a cost that may depend on the current state and control action. This cost is denoted by <span class="math inline">\(c_t(S_t, A_t)\)</span>. The system operates for a time horizon <span class="math inline">\(T\)</span>. During this time, it incurs a total cost <span class="math display">\[ \sum_{t=1}^T c_t(S_t, A_t). \]</span></p>
<p>The initial state <span class="math inline">\(S_1\)</span> and the noise process <span class="math inline">\(\{W_t\}_{t \ge 1}\)</span> are random variables defined on a common probability space (these are called <em>primitive random variables</em>) and are mutually independent. This seemingly benign assumption is critical for the theory that we present to go through.</p>
<p>Suppose we have to design such a controller. We are told the probability distribution of the initial state and the noise. We are also told the system update functions <span class="math inline">\((f_1, \dots, f_T)\)</span> and the cost functions <span class="math inline">\((c_1, \dots, c_T)\)</span>.</p>
<p>Our objective to determine a <strong>control policy</strong>, i.e., a function for choosing the control actions. The control policy can be as sophisticated as we want. In principle, it can analyze the entire history of observations and control actions to choose the current control action. Thus, the control action can be written as <span class="math display">\[ A_t = π_t(S_{1:t}, A_{1:t-1}),\]</span> where <span class="math inline">\(S_{1:t}\)</span> is a shorthand for <span class="math inline">\((S_1, \dots, S_t)\)</span> and a similar interpretation holds for <span class="math inline">\(A_{1:t-1})\)</span>. The function <span class="math inline">\(π_t\)</span> is called the <strong>control law</strong> at time <span class="math inline">\(t\)</span>.</p>
<p>We want to choose a <em>control policy</em> <span class="math inline">\(π = (π_1, \dots, π_T)\)</span> to minimize the expected total cost <span class="math display">\[ J(π) := \EXP\bigg[ \sum_{t=1}^T c_t(S_t, A_t) \bigg]. \]</span> How should we proceed?</p>
<p>At first glance, the problem looks intimidating. It appears that we have to design a very sophisticated controller: one that analyzes all past data to choose a control input. However, this is not the case. A remarkable result is that the optimal controller can discard all past data and choose the control input based only on the current state of the system. Formally, we have the following:</p>
<div id="thm-MDP-markov" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5.1 (Optimality of Markov policies)</strong></span> For the system model described above, there is no loss of optimality in choosing the control action according to <span class="math display">\[ A_t = π_t(S_t), \quad t=1, \dots, T.\]</span> Such a control policy is called a <em>Markov policy</em>.</p>
</div>
<p>In the context of the example presented at the beginning of this section, <a href="#thm-MDP-markov" class="quarto-xref">Theorem&nbsp;<span>5.1</span></a> says that the decision maker can decide whether to choose action <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> based on the current state, without any loss of optimality.</p>
<p>In general, <a href="#thm-MDP-markov" class="quarto-xref">Theorem&nbsp;<span>5.1</span></a> claims that the cost incurred by the best Markov policy is the same as the cost incurred by the best history dependent policy. This appears to be a tall claim, so lets see how we can prove it. The main idea of the proof is to repeatedly apply <a href="../stochastic-optimization/intro.html#blackwells-principle-of-irrelevant-information">Blackwell’s principle of irrelevant information</a> <span class="citation" data-cites="Blackwell1964">(<a href="../references.html#ref-Blackwell1964" role="doc-biblioref">Blackwell 1964</a>)</span></p>
<div id="lem-MDP-two-step-lemma" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 5.1 (Two-Step Lemma)</strong></span> Consider an MDP that operates for two steps (<span class="math inline">\(T=2\)</span>). Then there is no loss of optimality in restricting attention to a Markov control policy at time <span class="math inline">\(t=2\)</span>.</p>
</div>
<p>Note that <span class="math inline">\(π_1\)</span> is Markov because it can only depend <span class="math inline">\(S_1\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Fix <span class="math inline">\(π_1\)</span> and look at the problem of optimizing <span class="math inline">\(π_2\)</span>. The total cost is <span class="math display">\[ \EXP[ c_1(S_1, π_1(S_1)) + c_2(S_2, π_2(S_{1:2}, A_1)) ]\]</span> The choice of <span class="math inline">\(π_2\)</span> does not influence the first term. So, for a fixed <span class="math inline">\(π_1\)</span>, minimizing the total cost is the equivalent to minimizing the second term. Now, from Blackwell’s principle of irrelevant information, there exists a <span class="math inline">\(π_2^* \colon S_2 \mapsto A_2\)</span> such that for any <span class="math inline">\(π_2\)</span> <span class="math display">\[\EXP[c_2(S_2, π_2^*(S_2) ] \le \EXP[c_2(S_2, π_2(S_{1:2}, A_2) ].\]</span></p>
</div>
</div>
</div>
<div id="lem-three-step-lemma" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 5.2 (Three-Step Lemma)</strong></span> Consider an MDP that operates for three steps (<span class="math inline">\(T=3\)</span>). Assume that the control law <span class="math inline">\(π_3\)</span> at time <span class="math inline">\(t=3\)</span> is Markov, i.e., <span class="math inline">\(A_3 = π_3(S_3)\)</span>. Then, there is no loss of optimality in restricting attention to Markov control law at time <span class="math inline">\(t=2\)</span>.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Fix <span class="math inline">\(π_1\)</span> and <span class="math inline">\(π_3\)</span> and look at optimizing <span class="math inline">\(π_2\)</span>. The total cost is <span class="math display">\[ \EXP[ c_1(S_1, π_1(S_1)) + c_2(S_2, π_2(S_{1:2}, A_1)) + c_3(S_3, π_3(S_3)].\]</span></p>
<p>The choice of <span class="math inline">\(π_2\)</span> does not affect the first term. So, for a fixed <span class="math inline">\(π_1\)</span> and <span class="math inline">\(π_3\)</span>, minimizing the total cost is the same as minimizing the last two terms. Let us look at the last term carefully. Bu the law of iterated expectations, we have <span class="math display">\[ \EXP[ c_3(S_3, π_3(S_3) ] = \EXP[ \EXP[ c_3(S_3, π_3(S_3)) | S_2, A_2 ] ]. \]</span> Now, <span class="math display">\[\begin{align*}
  \EXP[ c_3(S_3, π_3(S_3)) | S_2 = s_2, A_2 = a_2 ] &amp;=
  \sum_{s_3 \in \ALPHABET S} c_3(s_3, π_3(s_3)) \\
  &amp;= \PR( w_2 \in \ALPHABET W : f_2(s_2, a_2, w_2) = s_3 )
  \\
  &amp;=: h_2(s_2, a_2).
\end{align*}\]</span> The key point is that <span class="math inline">\(h_2(s_2, a_2)\)</span> does not depend on <span class="math inline">\(π_1\)</span> or <span class="math inline">\(π_2\)</span>.</p>
<p>Thus, the total expected cost affected by the choice of <span class="math inline">\(π_2\)</span> can be written as <span class="math display">\[\begin{align*}
  \EXP[ c_2(S_2, A_2) + c_3(S_3, A_3) ] &amp;= \EXP[ c_2(S_2, A_2) + h_2(S_2, A_2)
  ] \\
  &amp;=: \EXP[ \tilde c_2(S_2, A_2) ].
\end{align*}\]</span> Now, by Blackwell’s principle of irrelevant information, there exists a <span class="math inline">\(π_2^* : S_2 \mapsto A_2\)</span> such that for any <span class="math inline">\(π_2\)</span>, we have <span class="math display">\[ \EXP[ \tilde c_2(S_2, π_2^*(S_2))] \le  \EXP[ \tilde c_2(S_2, π_2(S_{1:2},
A_1) ].\]</span></p>
</div>
</div>
</div>
<p>Now we have enough background to present the proof of optimality of Markov policies.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof of <a href="#thm-MDP-markov" class="quarto-xref">Theorem&nbsp;<span>5.1</span></a>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The main idea is that any system can be thought of as a two- or three-step system by aggregating time. Suppose that the system operates for <span class="math inline">\(T\)</span> steps. It can be thought of as a two-step system where <span class="math inline">\(t \in \{1, \dots, T - 1\}\)</span> corresponds to step 1 and <span class="math inline">\(t = T\)</span> corresponds to step 2. From the two-step lemma, there is no loss of optimality in restricting attention to Markov control law at step 2 (i.e., at time <span class="math inline">\(t=T\)</span>), i.e., <span class="math display">\[ A_T = π_T(S_T). \]</span></p>
<p>Now consider a system where we are using a Markov policy at time <span class="math inline">\(t=T\)</span>. This system can be thought of as a three-step system where <span class="math inline">\(t \in \{1, \dots,
T-2\}\)</span> corresponds to step 1, <span class="math inline">\(t = T-1\)</span> corresponds to step 2, and <span class="math inline">\(t=T\)</span> corresponds to step 3. Since the controller at time <span class="math inline">\(T\)</span> is Markov, the assumption of the three step lemma is satisfied. Thus, by that lemma, there is no loss of optimality in restricting attention to Markov controllers at step 2 (i.e., at time <span class="math inline">\(t=T-1\)</span>), i.e., <span class="math display">\[A_{T-1} = π_{T-1}(S_{T-1}).\]</span></p>
<p>Now consider a system where we are using a Markov policy at time <span class="math inline">\(t \in
\{T-1, T\}\)</span>. This can be thought of as a three-step system where <span class="math inline">\(t \in \{1,
\dots, T - 3\}\)</span> correspond to step 1, <span class="math inline">\(t = T-2\)</span> correspond to step 2, and <span class="math inline">\(t
\in \{T-1, T\}\)</span> correspond to step 3. Since the controllers at time <span class="math inline">\(t \in
\{T-1, T\}\)</span> are Markov, the assumption of the three-step lemma is satisfied. Thus, by that lemma, there is no loss of optimality in restricting attention to Markov controllers at step 2 (i.e., at time <span class="math inline">\(t=T-2\)</span>), i.e., <span class="math display">\[A_{T-2} = π_{T-2}(S_{T-2}).\]</span></p>
<p>Proceeding this way, we continue to think of the system as a three step system by different relabeling of time. Once we have shown that the controllers at times <span class="math inline">\(t \in \{s+1, s+2, \dots, T\}\)</span> are Markov, we relabel time as follows: <span class="math inline">\(t=\{1, \dots, s-1\}\)</span> corresponds to step 1, <span class="math inline">\(t = s\)</span> corresponds to step 2, and <span class="math inline">\(t \in \{s+1, \dots, T\}\)</span> corresponds to step 3. Since the controllers at time <span class="math inline">\(t \in \{s+1, \dots, T\}\)</span> are Markov, the assumption of the three-step lemma is satisfied. Thus, by that lemma, there is no loss of optimality in restricting attention to Markov controllers at stage 2 (i.e.&nbsp;at time <span class="math inline">\(s\)</span>), i.e., <span class="math display">\[A_τ = π_τ(S_τ).\]</span></p>
<p>Proceeding until <span class="math inline">\(s=2\)</span>, completes the proof.</p>
</div>
</div>
</div>
</section>
<section id="performance" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="performance"><span class="header-section-number">5.3</span> Performance of Markov policies</h2>
<p>We have shown that there is no loss of optimality to restrict attention to Markov policies. One of the advantages of Markov policies is that their performance can be computed recursively. In particular, given any Markov policy <span class="math inline">\(π = (π_1, \dots, π_T)\)</span>, define <em>the cost-to-go functions</em> or <em>value function</em> as follows: <span class="math display">\[V^{π}_t(s) = \EXP^π \bigg[ \sum_{τ = t}^{T} c_τ(S_τ, π_τ(S_τ)) \biggm| S_t =
s\bigg]. \]</span> Note that <span class="math inline">\(V^{π}_t(s)\)</span> only depends on the future policy <span class="math inline">\((π_t, \dots, π_T)\)</span>. These functions can be computed recursively as follows: we start with a terminal value function <span class="math inline">\(V^{π}_{T+1}(s) ≡ 0\)</span> and then for <span class="math inline">\(t \in \{T, T-1, \dots, 1\}\)</span>, recursively compute: <span class="math display">\[\begin{align}
  V^{π}_t(s) &amp;= \EXP^π \bigg[ \sum_{τ = t}^{T} c_τ(S_τ, π_τ(S_τ)) \biggm| S_t =
  s \bigg] \notag \\
  &amp;= \EXP^π \bigg[ c_t(s, π_t(s)) + \EXP^π \bigg[ \sum_{τ = t+1}^T
    c_τ(S_τ, π_τ(S_τ)) \biggm| S_{t+1} \bigg] \biggm| S_t = s \bigg]
  \notag \\
  &amp;= \EXP^π\big[ c_t(s, π_t(s)) + V^{π}_{t+1}(S_{t+1}; π) \big| S_t = s \big]. \label{eq:finite-policy-evaluation}
\end{align}\]</span></p>
<p>The formula of Eq.&nbsp;<span class="math inline">\(\eqref{eq:finite-policy-evaluation}\)</span> is called the <strong>policy evaluation formula.</strong></p>
<p>For the controlled Markov chain representation, the formula can be written in a vector form. In particular, we will think of <span class="math inline">\(V^π_t\)</span> to be a vector in <span class="math inline">\(\reals^n\)</span>, where <span class="math inline">\(n = \ABS{\ALPHABET S}\)</span>. For any policy <span class="math inline">\(π = (π_1, \dots, π_T)\)</span>, define the <span class="math inline">\(n × n\)</span> transition matrices <span class="math inline">\((P^{π}_1, \dots, P^{π}_T)\)</span> as <span class="math display">\[
  P^{π}_t(s'|s) = P_t(s'|s, π_t(s)),
  \quad t \in \{1,\dots, T\}.
\]</span> Furthermore, define <span class="math inline">\(n\)</span> dimensional cost vectors <span class="math inline">\((c^{π}_1, \dots, c^{π}_T)\)</span> as <span class="math display">\[
  c^π_t(s) = c_t(s, π_t(s)),
  \quad t \in \{1,\dots, T\}.
\]</span> Then, the policy evaluation formula <span class="math inline">\(\eqref{eq:finite-policy-evaluation}\)</span> is equivalent to the following: start with a terminal value function <span class="math inline">\(V^π_{T+1} ≡ 0\)</span> and then for <span class="math inline">\(t \in \{T, T-1,\dots, 1\}\)</span>, recursively compute: <span class="math display">\[
  V^{π}_t = c^{π}_t + P^{π}_t V^{π}_{t+1}.
\]</span></p>
<section id="exm-peak-control-continued" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="exm-peak-control-continued"><span class="header-section-number">5.3.1</span> <a href="#exm-peak-control" class="quarto-xref">Example&nbsp;<span>5.1</span></a> (continued)</h3>
<p>As an example, consider the following time-homogeneous policy <a href="#exm-peak-control" class="quarto-xref">Example&nbsp;<span>5.1</span></a>: <span class="math display">\[
  π_t(s) = \begin{cases}
    1 &amp; \text{if } |s| = 2 \\
    0 &amp; \text{otherwise}
  \end{cases}
\]</span> Suppose <span class="math inline">\(p = 1\)</span>, i.e., <span class="math inline">\(c(s,a) = s^2 + a\)</span>. We now compute the value function <span class="math inline">\(\{V^{π}_t\}_{t=1}^T\)</span> for <span class="math inline">\(T = 5\)</span>.</p>
<p>For this policy <span class="math display">\[
  c^{π} = \MATRIX{ 5 \\ 1 \\ 0 \\ 1 \\  5 }
  \quad\text{and}\quad
  \def\1{\tfrac 14}
  \def\2{\tfrac 34}
  \def\3{\tfrac 12}
  P^π = \MATRIX{ \1&amp; \2&amp;  0&amp;  0&amp;  0\\
                \3&amp; 0 &amp; \3&amp;  0&amp;  0\\
                0&amp;  \3&amp;  0&amp;  \3&amp; 0\\
                0&amp;  0&amp;  \3&amp;   0&amp; \3 \\
                0&amp;  0&amp;   0&amp;  \2&amp; \1}
\]</span> We start with <span class="math inline">\(V^π_{t+1} = \VEC(0,0,0,0,0)\)</span> and run the following recursion.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>cπ <span class="op">=</span> [<span class="fl">5</span>, <span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">5</span>] </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>Pπ <span class="op">=</span> [<span class="fl">1</span><span class="op">//</span><span class="fl">4</span>  <span class="fl">3</span><span class="op">//</span><span class="fl">4</span>  <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">0</span> </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>      <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">0</span>     <span class="fl">0</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>      <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">0</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>      <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">2</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>      <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">3</span><span class="op">//</span><span class="fl">4</span>  <span class="fl">1</span><span class="op">//</span><span class="fl">4</span>]</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="fl">5</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="fu">size</span>(cπ,<span class="fl">1</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>Vπ <span class="op">=</span> [ <span class="fu">zeros</span>(n) for t <span class="op">∈</span> <span class="fl">1</span><span class="op">:</span>T<span class="op">+</span><span class="fl">1</span> ]</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="op">∈</span> T<span class="op">:-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  Vπ[t] <span class="op">=</span> cπ <span class="op">+</span> Pπ<span class="op">*</span>Vπ[t<span class="op">+</span><span class="fl">1</span>]</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(Vπ)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>6-element Vector{Vector{Float64}}:
 [13.3515625, 9.046875, 7.4375, 9.046875, 13.3515625]
 [11.09375, 7.4375, 5.0, 7.4375, 11.09375]
 [9.375, 5.0, 3.5, 5.0, 9.375]
 [7.0, 3.5, 1.0, 3.5, 7.0]
 [5.0, 1.0, 0.0, 1.0, 5.0]
 [0.0, 0.0, 0.0, 0.0, 0.0]</code></pre>
</div>
</div>
<p><a href="#fig-peak-evaluation" class="quarto-xref">Figure&nbsp;<span>5.3</span></a> shows the value functions computed as part of the policy evaluation.</p>
<div id="fig-peak-evaluation" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-peak-evaluation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/peak-control-evaluation1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-peak-evaluation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.3: Value function for policy evaluation of <a href="#exm-peak-control" class="quarto-xref">Example&nbsp;<span>5.1</span></a>. Note that the value functions are computed by proceeding backwards in time.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="DP" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="DP"><span class="header-section-number">5.4</span> Dynamic Programming Decomposition</h2>
<p>Now we are ready to state the main result for MDPs.</p>
<div id="thm-MDP-DP" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5.2 (Dynamic program)</strong></span> Recursive define <em>value functions</em> <span class="math inline">\(\{V^*_t\}_{t = 1}^{T+1} \colon \ALPHABET S
\to \reals\)</span> as follows: <span class="math display">\[ \begin{equation} \label{eq:DP-1}
  V^*_{T+1}(s) = 0
\end{equation} \]</span> and for <span class="math inline">\(t \in \{T, \dots, 1\}\)</span>: <span class="math display">\[\begin{align}
   Q^*_t(s,a) &amp;= c(s,a) + \EXP[ V^*_{t+1}(S_{t+1}) | S_t = s, A_t = a]
   \nonumber \\
   &amp;= c(s,a) + \EXP[ V^*_{t+1}(f_t(s,a,W_t)) ], \label{eq:DP-2}
\end{align}\]</span> and define <span class="math display">\[ \begin{equation} \label{eq:DP-3}
  V^*_t(s) = \min_{a \in \ALPHABET A} Q^*_t(s,a).
\end{equation} \]</span> Then, a Markov policy is optimal if and only if it satisfies <span class="math display">\[ \begin{equation} \label{eq:verification}
  π_t^*(s) = \arg \min_{a \in \ALPHABET A} Q_t(s,a).
\end{equation} \]</span></p>
</div>
<p>For the controlled Markov chain representation, the dynamic program of <a href="#thm-MDP-DP" class="quarto-xref">Theorem&nbsp;<span>5.2</span></a> can be written more succinctly. We will view <span class="math inline">\(\{V^*_t\}_{t=1}^T\)</span> as vectors in <span class="math inline">\(\reals^n\)</span>, where <span class="math inline">\(n = \ABS{\ALPHABET S}\)</span>. Moreover, we will view <span class="math inline">\(\{Q^*_t\}_{t=1}^T\)</span> and <span class="math inline">\(\{c_t\}_{t=1}^T\)</span> as matrices in <span class="math inline">\(\reals^{n × m}\)</span>, where <span class="math inline">\(m = \ABS{\ALPHABET A}\)</span>.</p>
<p>Then, the dynamic program of <a href="#thm-MDP-DP" class="quarto-xref">Theorem&nbsp;<span>5.2</span></a> may be written as follows: start with a terminal value function <span class="math inline">\(V^*_{T+1} ≡ 0\)</span> and then for <span class="math inline">\(t \in \{T, T-1, \dots, 1\}\)</span>, recursively compute: <span class="math display">\[\begin{align*}
  Q^*_t &amp;= c_t + [ P_t(1) V^*_{t+1} \mid P_t(2) V^*_{t+1} \mid \cdots \mid P_t(m) V^*_{t+1} ], \\
  V^*_t &amp;= \min(Q^*_t, \hbox{\tt dim}=2), \\
  π^*_t &amp;= \arg\min(Q^*_t, \hbox{\tt dim}=2).
\end{align*}\]</span></p>
<section id="exm-peak-control-continued-1" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="exm-peak-control-continued-1"><span class="header-section-number">5.4.1</span> <a href="#exm-peak-control" class="quarto-xref">Example&nbsp;<span>5.1</span></a> (continued)</h3>
<p>Now we present the dynamic programming solution for <a href="#exm-peak-control" class="quarto-xref">Example&nbsp;<span>5.1</span></a>:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We use the default indexing (1,...,n) for convenience. </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>(n,m) <span class="op">=</span> (<span class="fl">5</span>,<span class="fl">2</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>S <span class="op">=</span> <span class="fl">1</span><span class="op">:</span>n</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> <span class="fl">1</span><span class="op">:</span>m</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="fl">5</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> [ <span class="fu">zeros</span>(n,n) for a <span class="op">∈</span> A ]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>P[<span class="fl">1</span>] <span class="op">=</span> [<span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">0</span> </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">0</span>     <span class="fl">0</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">0</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">2</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>]</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>P[<span class="fl">2</span>] <span class="op">=</span> [<span class="fl">1</span><span class="op">//</span><span class="fl">4</span>  <span class="fl">3</span><span class="op">//</span><span class="fl">4</span>  <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">0</span> </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="fl">1</span><span class="op">//</span><span class="fl">4</span>  <span class="fl">0</span>     <span class="fl">3</span><span class="op">//</span><span class="fl">4</span>  <span class="fl">0</span>     <span class="fl">0</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">4</span>  <span class="fl">1</span><span class="op">//</span><span class="fl">2</span>  <span class="fl">1</span><span class="op">//</span><span class="fl">4</span>  <span class="fl">0</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">3</span><span class="op">//</span><span class="fl">4</span>  <span class="fl">0</span>     <span class="fl">1</span><span class="op">//</span><span class="fl">4</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">0</span>     <span class="fl">3</span><span class="op">//</span><span class="fl">4</span>  <span class="fl">1</span><span class="op">//</span><span class="fl">4</span>]</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> <span class="fu">zeros</span>(n,m)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> s <span class="op">∈</span> S, a <span class="op">∈</span> A</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># use s-3 and a-1 to convert to "natural" indices -2:2 and 0:1</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>  c[s,a] <span class="op">=</span> (s<span class="op">-</span><span class="fl">3</span>)<span class="op">^</span><span class="fl">2</span> <span class="op">+</span> (a<span class="op">-</span><span class="fl">1</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> [ <span class="fu">zeros</span>(n)     for t <span class="op">∈</span> <span class="fl">1</span><span class="op">:</span>T<span class="op">+</span><span class="fl">1</span> ]</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="cn">π</span> <span class="op">=</span> [ <span class="fu">zeros</span>(<span class="dt">Int</span>,n) for t <span class="op">∈</span> <span class="fl">1</span><span class="op">:</span>T   ]</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="op">∈</span> T<span class="op">:-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>  Q <span class="op">=</span> c <span class="op">+</span> <span class="fu">hcat</span>(P[<span class="fl">1</span>]<span class="op">*</span>V[t<span class="op">+</span><span class="fl">1</span>], P[<span class="fl">2</span>]<span class="op">*</span>V[t<span class="op">+</span><span class="fl">1</span>])</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Could be done more efficiently with a single pass</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>  V[t] <span class="op">=</span> <span class="fu">vec</span>(<span class="fu">minimum</span>(Q, dims<span class="op">=</span><span class="fl">2</span>))</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Subtract 1 to get to "natural" indices 0:1</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>  <span class="cn">π</span>[t] <span class="op">=</span> <span class="fu">argmin</span>.(<span class="fu">eachrow</span>(Q)) <span class="op">.-</span> <span class="fl">1</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(V)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="cn">π</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>6-element Vector{Vector{Float64}}:
 [12.4453125, 7.8984375, 6.40625, 7.8984375, 12.4453125]
 [10.46875, 6.4375, 4.375, 6.4375, 10.46875]
 [8.75, 4.375, 3.0, 4.375, 8.75]
 [6.5, 3.0, 1.0, 3.0, 6.5]
 [4.0, 1.0, 0.0, 1.0, 4.0]
 [0.0, 0.0, 0.0, 0.0, 0.0]</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>5-element Vector{Vector{Int64}}:
 [1, 1, 1, 1, 1]
 [1, 1, 0, 1, 1]
 [0, 1, 0, 1, 0]
 [0, 0, 0, 0, 0]
 [0, 0, 0, 0, 0]</code></pre>
</div>
</div>
<p><a href="#fig-peak-optimal" class="quarto-xref">Figure&nbsp;<span>5.4</span></a> shows the value functions and optimal policy computed from the dynamic program</p>
<div id="fig-peak-optimal" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-peak-optimal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/peak-control-optimal1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-peak-optimal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.4: Optimal value function and optimal policy for <a href="#exm-peak-control" class="quarto-xref">Example&nbsp;<span>5.1</span></a>. The red color indicates that the optimal action is <span class="math inline">\(1\)</span>; black indicates that the optimal action is <span class="math inline">\(0\)</span>. Note that the computations are done by proceeding backwards in time.
</figcaption>
</figure>
</div>
</section>
<section id="back-to-the-proof" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="back-to-the-proof"><span class="header-section-number">5.4.2</span> Back to the proof</h3>
<p>Instead of proving <a href="#thm-MDP-DP" class="quarto-xref">Theorem&nbsp;<span>5.2</span></a>, we prove a related result.</p>
<div id="thm-comparison-principle" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5.3 (The comparison principle)</strong></span> For any Markov policy <span class="math inline">\(π\)</span> <span class="math display">\[ V^{π}_t(s) \ge V_t(s) \]</span> with equality at <span class="math inline">\(t\)</span> if and only if the <em>future policy</em> <span class="math inline">\(π_{t:T}\)</span> satisfies the verification step \eqref{eq:verification}.</p>
</div>
<p>Note that the comparison principle immediately implies that the policy obtained using dynamic programming is optimal.</p>
<p>The comparison principle also allows us to interpret the value functions. The value function at time <span class="math inline">\(t\)</span> is the minimum of all the cost-to-go functions over all future policies. The comparison principle also allows us to interpret the optimal policy (the interpretation is due to Bellman and is colloquially called Bellman’s principle of optimality).</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bellman’s principle of optimality.
</div>
</div>
<div class="callout-body-container callout-body">
<p>An optimal policy has the property that whatever the initial state and the initial decisions are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof of the comparison principle
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The proof proceeds by backward induction. Consider any Markov policy <span class="math inline">\(π =
(π_1, \dots, π_T)\)</span>. For <span class="math inline">\(t = T\)</span>, <span class="math display">\[ \begin{align*}
  V_T(s) &amp;= \min_{a \in \ALPHABET A} Q_T(s,a) \\
  &amp;\stackrel{(a)}= \min_{a \in \ALPHABET A} c_T(s,a) \\
  &amp;\stackrel{(b)}\le c_T(s, π_T(s)) \\
  &amp;\stackrel{(c)}= V^{π}_T(s),
\end{align*} \]</span> where <span class="math inline">\((a)\)</span> follows from the definition of <span class="math inline">\(Q_T\)</span>, <span class="math inline">\((b)\)</span> follows from the definition of minimization, and <span class="math inline">\((c)\)</span> follows from the definition of <span class="math inline">\(J_T\)</span>. Equality holds in <span class="math inline">\((b)\)</span> iff the policy <span class="math inline">\(π_T\)</span> is optimal. This result forms the basis of induction.</p>
<p>Now assume that the statement of the theorem is true for <span class="math inline">\(t+1\)</span>. Then, for <span class="math inline">\(t\)</span> <span class="math display">\[ \begin{align*}
  V_t(s) &amp;= \min_{a \in \ALPHABET A} Q_t(s,a) \\
  &amp;\stackrel{(a)}= \min_{a \in \ALPHABET A} \Big\{
  c_t(s,a) + \EXP[ V_{t+1}(S_{t+1}) | S_t = s, A_t = a]
  \Big\}
  \\
  &amp;\stackrel{(b)}\le  \Big\{
  c_t(s,π_t(s)) + \EXP[ V_{t+1}(S_{t+1}) | S_t = s, A_t = π_t(s)]
  \Big\} \\
  &amp;\stackrel{(c)}\le  \Big\{
  c_t(s,π_t(s)) + \EXP[ J_{t+1}(S_{t+1}; π) | S_t = s, A_t = π_t(s)]
  \Big\} \\
  &amp;\stackrel{(d)}= V^{π}_t(s),
\end{align*} \]</span> where <span class="math inline">\((a)\)</span> follows from the definition of <span class="math inline">\(Q_t\)</span>, <span class="math inline">\((b)\)</span> follows from the definition of minimization, <span class="math inline">\((c)\)</span> follows from the induction hypothesis, and <span class="math inline">\((d)\)</span> follows from the definition of <span class="math inline">\(J_t\)</span>. We have equality in step <span class="math inline">\((b)\)</span> iff <span class="math inline">\(π_t\)</span> satisfies the verification step \eqref{eq:verification} and have equality in step <span class="math inline">\((c)\)</span> iff <span class="math inline">\(π_{t+1:T}\)</span> is optimal (this is part of the induction hypothesis). Thus, the result is true for time <span class="math inline">\(t\)</span> and, by the principle of induction, is true for all time.</p>
</div>
</div>
</div>
</section>
</section>
<section id="more-examples" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="more-examples"><span class="header-section-number">5.5</span> More examples</h2>
<section id="machine-replacement" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="machine-replacement"><span class="header-section-number">5.5.1</span> Machine replacement</h3>
<div id="exm-machine-replacement" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.2 (Machine replacement)</strong></span> Consider a manufacturing process, where the machine used for manufacturing deteriorates over time. Let <span class="math inline">\(\ALPHABET S = \{0, 1, \dots n \}\)</span> represent the condition of the machine. The higher the value of <span class="math inline">\(s\)</span>, the worse the condition of the equipment.</p>
<p>A decision maker observes the state of the machine and has two options: continue operating the machine or replace it with a a new and identical piece of equipment. Operating the machine is state <span class="math inline">\(s\)</span> costs <span class="math inline">\(h(s)\)</span>, where <span class="math inline">\(h(⋅)\)</span> is a weakly increasing function; replace the machine costs a constant amount <span class="math inline">\(K\)</span>.</p>
<p>When the machine is operated, it’s state deteriorates according to <span class="math display">\[
  S_{t+1} = \min( S_t + W_t , n)
\]</span> where <span class="math inline">\(\{W_t\}_{t \ge 1}\)</span> is an i.i.d.&nbsp;process with PMF <span class="math inline">\(μ\)</span>.</p>
</div>
<p>The above system may be modelled as an MDP with state space <span class="math inline">\(\ALPHABET S\)</span> and action space <span class="math inline">\(\ALPHABET A = \{0, 1\}\)</span> where <span class="math inline">\(0\)</span> means operating the machine and <span class="math inline">\(1\)</span> means replacing the machine.</p>
<p>For instance, consider <span class="math inline">\(n = 5\)</span> and <span class="math inline">\(W \sim \text{Bernoulli}(p)\)</span>. The evolution of the Markov chain under action <span class="math inline">\(A_t = 0\)</span> and <span class="math inline">\(A_t = 1\)</span> are shown in <a href="monotone-mdps.html#fig-machine-replacement" class="quarto-xref">Figure&nbsp;<span>8.1</span></a>.</p>
<div id="fig-machine-replacement" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-machine-replacement-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/machine-replacement1.svg" class="img-fluid figure-img"></p>
<figcaption>Dynamics under action <span class="math inline">\(A_t = 0\)</span></figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/machine-replacement2.svg" class="img-fluid figure-img"></p>
<figcaption>Dynamics under action <span class="math inline">\(A_t = 1\)</span></figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-machine-replacement-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.5: State dynamics for the MDP of <a href="#exm-machine-replacement" class="quarto-xref">Example&nbsp;<span>5.2</span></a>
</figcaption>
</figure>
</div>
<p>Thus, <span class="math display">\[
  P(0) = \MATRIX{q&amp; p&amp; 0&amp; 0&amp; 0&amp; 0\\
                 0&amp; q&amp; p&amp; 0&amp; 0&amp; 0\\
                 0&amp; 0&amp; q&amp; p&amp; 0&amp; 0\\
                 0&amp; 0&amp; 0&amp; q&amp; p&amp; 0\\
                 0&amp; 0&amp; 0&amp; 0&amp; q&amp; p\\
                 0&amp; 0&amp; 0&amp; 0&amp; 0&amp; 1}
  \quad\hbox{and}\quad
  P(1) = \MATRIX{1&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0\\
                 1&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0\\
                 1&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0\\
                 1&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0\\
                 1&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0\\
                 1&amp; 0&amp; 0&amp; 0&amp; 0&amp; 0}
\]</span> where we have set <span class="math inline">\(q = 1-p\)</span> for notational convenience.</p>
<p>The per-step cost is given by <span class="math display">\[
  c(s,a) = h(s) + λa.
\]</span></p>
<p>Solving the DP for <span class="math inline">\(p=0.2\)</span>, <span class="math inline">\(λ=10\)</span>, and <span class="math inline">\(T=5\)</span> gives the following:</p>
<div class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">SparseArrays</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We use the default indexing (1,...,n) for convenience. </span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>(n,m) <span class="op">=</span> (<span class="fl">6</span>,<span class="fl">2</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>S <span class="op">=</span> <span class="fl">1</span><span class="op">:</span>n</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> <span class="fl">1</span><span class="op">:</span>m</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="fl">5</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>λ <span class="op">=</span> <span class="fl">10</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> <span class="fl">1</span><span class="op">-</span>p</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> [ <span class="fu">spzeros</span>(n,n) for a <span class="op">∈</span> A ]</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> S</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>  P[<span class="fl">1</span>][i,i] <span class="op">=</span> q</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>  P[<span class="fl">1</span>][i,<span class="fu">min</span>(i<span class="op">+</span><span class="fl">1</span>,n)] <span class="op">+=</span> p</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>  P[<span class="fl">2</span>][i,<span class="fl">1</span>] <span class="op">=</span> <span class="fl">1</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> <span class="fu">zeros</span>(n,m)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> s <span class="op">∈</span> S, a <span class="op">∈</span> A</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># use s-1 and a-1 to convert to "natural" indices 0:5 and 0:1</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>  c[s,a] <span class="op">=</span> <span class="fl">2</span>(s<span class="op">-</span><span class="fl">1</span>) <span class="op">+</span> <span class="fu">λ*</span>(a<span class="op">-</span><span class="fl">1</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>V <span class="op">=</span> [ <span class="fu">zeros</span>(n)     for t <span class="op">∈</span> <span class="fl">1</span><span class="op">:</span>T<span class="op">+</span><span class="fl">1</span> ]</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="cn">π</span> <span class="op">=</span> [ <span class="fu">zeros</span>(<span class="dt">Int</span>,n) for t <span class="op">∈</span> <span class="fl">1</span><span class="op">:</span>T   ]</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="op">∈</span> T<span class="op">:-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>  Q <span class="op">=</span> c <span class="op">+</span> <span class="fu">hcat</span>(P[<span class="fl">1</span>]<span class="op">*</span>V[t<span class="op">+</span><span class="fl">1</span>], P[<span class="fl">2</span>]<span class="op">*</span>V[t<span class="op">+</span><span class="fl">1</span>])</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Could be done more efficiently with a single pass</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>  V[t] <span class="op">=</span> <span class="fu">vec</span>(<span class="fu">minimum</span>(Q, dims<span class="op">=</span><span class="fl">2</span>))</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Subtract 1 to get to "natural" indices 0:1</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>  <span class="cn">π</span>[t] <span class="op">=</span> <span class="fu">argmin</span>.(<span class="fu">eachrow</span>(Q)) <span class="op">.-</span> <span class="fl">1</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(V)</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="fu">display</span>(<span class="cn">π</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<pre><code>6-element Vector{Vector{Float64}}:
 [4.000000000000001, 13.360000000000003, 16.4, 18.4, 20.4, 22.4]
 [2.4000000000000004, 10.400000000000002, 15.2, 17.2, 19.2, 21.2]
 [1.2000000000000002, 7.200000000000001, 13.200000000000001, 16.4, 18.4, 20.4]
 [0.4, 4.4, 8.4, 12.4, 16.4, 20.0]
 [0.0, 2.0, 4.0, 6.0, 8.0, 10.0]
 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>5-element Vector{Vector{Int64}}:
 [0, 0, 1, 1, 1, 1]
 [0, 0, 1, 1, 1, 1]
 [0, 0, 0, 1, 1, 1]
 [0, 0, 0, 0, 0, 0]
 [0, 0, 0, 0, 0, 0]</code></pre>
</div>
</div>
<p><a href="#fig-machine-replacement-plot" class="quarto-xref">Figure&nbsp;<span>5.6</span></a> shows the optimal value function and optimal policy as a function of time.</p>
<div id="fig-machine-replacement-plot" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-machine-replacement-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/machine-replacement-plot1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-machine-replacement-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.6: Optimal value function and optimal policy for <a href="#exm-machine-replacement" class="quarto-xref">Example&nbsp;<span>5.2</span></a>. The red color indicates that the optimal action is <span class="math inline">\(1\)</span>; black indicates that the optimal action is <span class="math inline">\(0\)</span>. Note that the computations are done by proceeding backwards in time.
</figcaption>
</figure>
</div>
<!-- TODO:
#### Rate control/admission control of a queue

-->
</section>
</section>
<section id="variations-of-a-theme" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="variations-of-a-theme"><span class="header-section-number">5.6</span> Variations of a theme</h2>
<section id="sec-cost-depending-on-next-state" class="level3" data-number="5.6.1">
<h3 data-number="5.6.1" class="anchored" data-anchor-id="sec-cost-depending-on-next-state"><span class="header-section-number">5.6.1</span> Cost depends on next state</h3>
<p>In the basic model that we have considered above, we assumed that the per-step cost depends only on the current state and current actions. In some applications, such as the <a href="inventory-management.html">inventory management</a>, it is more natural to have a cost function where the cost depends on the current state, current action, and the next state. Conceptually, such problems can be treated in the same way as the standard model.</p>
<p>In particular, suppose we have a per-step cost given by <span class="math inline">\(c_t(S_t,A_t,S_{t+1})\)</span>, where the objective is to minimize <span class="math display">\[ J(π) = \EXP\Bigl[ \sum_{t=1}^T c_t(S_t, A_t, S_{t+1}) \Bigr]. \]</span></p>
<p>Define <span class="math display">\[ \tilde c_t(s, a) = \EXP[ c_t(s, a, S_{t+1}) | S_t = s, A_t = a ]
= \EXP[ c_t(s,a, f_t(s,a, W_t) ]. \]</span> Then, by the towering property of conditional expectation, we can write</p>
<p><span class="math display">\[ \begin{align*}
J(π) &amp;= \EXP\Bigl[ \sum_{t=1}^T \EXP[ c_t(S_t, A_t, S_{t+1}) | S_t, A_t] \Bigr] \\
&amp;= \EXP\Bigl[ \sum_{t=1}^T \tilde c_t(S_t, A_t) \Bigr].
\end{align*} \]</span></p>
<p>Thus, we can equivalently consider this as our standard model with the per-step cost given by <span class="math inline">\(\tilde c_t(S_t, A_t)\)</span>. We can write the recursive step of the dynamic program as follows: <span class="math display">\[ Q^*_t(s,a) = \EXP[ c_t(s,a, S_{t+1}) + V^*_{t+1}(S_{t+1}) | S_t = s, A_t = a ].\]</span></p>
<p>For numerically solving the dynamic program when the cost is time-homogeneous (i.e., does not depend on <span class="math inline">\(t\)</span>), it is more efficient to compute <span class="math inline">\(\tilde c\)</span> once and recuse that in the dynamic program recursion.</p>
</section>
<section id="discounted-cost" class="level3" data-number="5.6.2">
<h3 data-number="5.6.2" class="anchored" data-anchor-id="discounted-cost"><span class="header-section-number">5.6.2</span> Discounted cost</h3>
<p>In some applications, it is common to consider a discounted expected cost given by <span class="math display">\[ J(π) = \EXP\Bigl[ \sum_{t=1}^T γ^{t-1} c_t(S_t, A_t) \Bigr] \]</span> where <span class="math inline">\(γ \in (0,1)\)</span> is called the discount factor.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Discount Factor
</div>
</div>
<div class="callout-body-container callout-body">
<p>The idea of using discounting in MDPs is due to <span class="citation" data-cites="Blackwell1965">Blackwell (<a href="../references.html#ref-Blackwell1965" role="doc-biblioref">1965</a>)</span>.</p>
<p>There are two interpretations of the discount factor <span class="math inline">\(γ\)</span>. The first interpretation is an economic interpretation to determine the <em>present value</em> of a utility that will be received in the future. For example, suppose a decision maker is indifferent between receiving 1 dollar today or <span class="math inline">\(s\)</span> dollars tomorrow. This means that the decision maker discounts the future at a rate <span class="math inline">\(1/s\)</span>, so <span class="math inline">\(γ = 1/s\)</span>.</p>
<p>The second interpretation is that of an absorbing state. Suppose we are operating a machine that generates a value of $1 each day. However, there is a probability <span class="math inline">\(p\)</span> that the machine will break down at the end of the day. Thus, the expected return for today is $1 while the expected return for tomorrow is <span class="math inline">\((1-p)\)</span> (which is the probability that the machine is still working tomorrow). In this case, the discount factor is defined as <span class="math inline">\((1-p)\)</span>. See <span class="citation" data-cites="Shwartz2001">Shwartz (<a href="../references.html#ref-Shwartz2001" role="doc-biblioref">2001</a>)</span> for a detailed discussion of this alternative.</p>
</div>
</div>
<p>The recursive step of the dynamic program for such models can be written as <span class="math display">\[ Q^*_t(s,a) = c_t(s,a) + γ \, \EXP[ V^*_{t+1}( S_{t+1}) | S_t = s, A_t = a ].\]</span></p>
</section>
<section id="multiplicative-cost" class="level3" data-number="5.6.3">
<h3 data-number="5.6.3" class="anchored" data-anchor-id="multiplicative-cost"><span class="header-section-number">5.6.3</span> Multiplicative cost</h3>
<p>So far, we have assumed that the cost is additive. The dynamic proramming decomposition also works for models with multiplicative cost. In particular, suppose that the performance of any policy is given by <span class="math display">\[ J(π) = \EXP\Bigl[ \prod_{t=1}^T c_t(S_t, A_t) \Bigr] \]</span> where the per-step cost function is positive. Then, it can be shown that the optimal policy is given by the following dynamic program.</p>
<div id="prp-DP-multiplicative" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 5.1 (Dynamic Program for multiplicative cost)</strong></span> Initialize <span class="math inline">\(V_{T+1}(s) = 1\)</span> and recursively compute <span class="math display">\[ \begin{align*}
Q^*_t(s,a) &amp;= c_t(s,a) \EXP[ V^*_{t+1}(S_{t+1}) | S_t = s, A_t = a ], \\
V^*_t(s) &amp;= \min_{a \in \ALPHABET A} Q^*_t(s,a).
\end{align*} \]</span></p>
</div>
</section>
<section id="exponential-cost" class="level3" data-number="5.6.4">
<h3 data-number="5.6.4" class="anchored" data-anchor-id="exponential-cost"><span class="header-section-number">5.6.4</span> Exponential cost function</h3>
<p>A special class of multiplicative cost function is exponential of sum: <span class="math display">\[J(π) = \EXP\Bigl[ \exp\Bigl( \theta \sum_{t=1}^T c_t(S_t, A_t) \Bigr) \Bigr]. \]</span></p>
<p>When <span class="math inline">\(\theta &gt; 0\)</span>, the above captures risk-averse preferences and when <span class="math inline">\(\theta &lt; 0\)</span>, it corresponds to risk-seeking preferences. This is equivalent to a multiplicative cost <span class="math display">\[J(π) = \EXP\Bigl[ \prod_{t=1}^T \exp( \theta c_t(S_t, A_t)) \Bigr]. \]</span> Therefore, the dynamic program for multiplicative cost is also applicable for this model.</p>
<p>See notes on <a href="../risk-sensitive/risk-sensitive-mdps.html">risk-sensitive MDPs</a> for more details</p>
</section>
<section id="optimal-stopping" class="level3" data-number="5.6.5">
<h3 data-number="5.6.5" class="anchored" data-anchor-id="optimal-stopping"><span class="header-section-number">5.6.5</span> Optimal stopping</h3>
<p>Let <span class="math inline">\(\{S_t\}_{t \ge 1}\)</span> be a Markov chain. At each time <span class="math inline">\(t\)</span>, a decision maker observes the state <span class="math inline">\(S_t\)</span> of the Markov chain and decides whether to continue or stop the process. If the decision maker decides to continue, he incurs a <em>continuation cost</em> <span class="math inline">\(c_t(S_t)\)</span> and the state evolves. If the DM decides to stop, he incurs a <em>stopping cost</em> of <span class="math inline">\(d_t(S_t)\)</span> and the problem is terminated. The objective is to determine an optimal <em>stopping time</em> <span class="math inline">\(\tau\)</span> to minimize <span class="math display">\[J(\tau) := \EXP\bigg[ \sum_{t=1}^{\tau-1} c_t(S_t) + d_\tau(S_\tau)
\bigg].\]</span></p>
<p>Such problems are called <em>Optimal stopping problems</em>.</p>
<p>Define the <em>cost-to-go function</em> of any stopping rule as <span class="math display">\[V^{\tau}_t(s) = \EXP\bigg[ \sum_{τ = t}^{\tau - 1} c_{\tau}(S_t) +
d_\tau(S_\tau) \,\bigg|\, \tau &gt; t \bigg]\]</span> and the <em>value function</em> as <span class="math display">\[V^*_t(s) = \inf_{\tau} V^{\tau}_t(s). \]</span> Then, it can be shown that the value functions satisfy the following recursion:</p>
<div id="prp-DP-stopping" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 5.2</strong></span> <strong>Dynamic Program for optimal stopping</strong> <span class="math display">\[ \begin{align*}
V^*_T(s) &amp;= s_T(s) \\
V^*_t(s) &amp;= \min\{ s_t(s), c_t(s) + \EXP[ V^*_{t+1}(S_{t+1}) | S_t = s].
\end{align*}\]</span></p>
</div>
<p>See the notes on <a href="../mdps/optimal-stopping.html">optimal stopping</a> for more details.</p>
</section>
<section id="minimax-setup" class="level3" data-number="5.6.6">
<h3 data-number="5.6.6" class="anchored" data-anchor-id="minimax-setup"><span class="header-section-number">5.6.6</span> Minimax setup</h3>
<p><em>To be written</em></p>
</section>
</section>
<section id="sec-mdp-cts-spaces" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="sec-mdp-cts-spaces"><span class="header-section-number">5.7</span> Continuous state and action spaces</h2>
<p>The fundamental ideas discussed above also hold for continuous state and action spaces provided one carefully deals with measurability. We first fix some notation:</p>
<ul>
<li>For a set <span class="math inline">\(\ALPHABET S\)</span>, let <span class="math inline">\(\mathscr B(\ALPHABET S)\)</span> denote the Borel sigma-algebra on <span class="math inline">\(\ALPHABET S\)</span>.</li>
<li>We use <span class="math inline">\(\ALPHABET M(\ALPHABET X, \ALPHABET Y)\)</span> to denote the set of measurable functions from the space <span class="math inline">\(\ALPHABET X\)</span> to the space <span class="math inline">\(\ALPHABET Y\)</span> (we implicitly assume that the sigma-algebras on <span class="math inline">\(\ALPHABET X\)</span> and <span class="math inline">\(\ALPHABET Y\)</span> is the respective Borel sigma-algebras). When <span class="math inline">\(\ALPHABET Y\)</span> is <span class="math inline">\(\reals\)</span>, we will sometimes use the notation <span class="math inline">\(\ALPHABET M(\ALPHABET X)\)</span>.</li>
</ul>
<!--
2. Let $\ALPHABET M_{∞}(\ALPHABET X)$ denote the set of measurable real valued functions with bounded sup-norm, i.e., 
   $$
    \ALPHABET M_{∞}(\ALPHABET X) = 
    \bigl\{ f \in \ALPHABET M(\ALPHABET X) : \| f \|_{∞} < ∞ \bigr\}.
   $$
-->
<p>In order to talk about <em>expected cost</em>, in continuous state spaces we have to assume that the per-step cost is measurable, i.e., <span class="math inline">\(c \in \ALPHABET M(\ALPHABET S × \ALPHABET A)\)</span>, and the <span class="math inline">\(P \colon \ALPHABET S × \ALPHABET A × \mathscr B(\ALPHABET S) \to [0,1]\)</span> is a stochastic kernel, i.e., for every <span class="math inline">\((s,a) \in \ALPHABET S × \ALPHABET A\)</span>, <span class="math inline">\(p(s,a,\cdot)\)</span> is probability measure on <span class="math inline">\(\ALPHABET S\)</span>, and for every <span class="math inline">\(B \in \ALPHABET S\)</span>, the function <span class="math inline">\(p(\cdot, \cdot, B) \in \ALPHABET M(\ALPHABET S × \ALPHABET A)\)</span>. These assumption imply that for every measurable policy <span class="math inline">\(π \in \ALPHABET M(\ALPHABET S, \ALPHABET A)\)</span>, the performance <span class="math inline">\(J(\pi)\)</span> is well defined. However, these assumptions are not sufficient to establish the optimality of dynamic programmming.</p>
<p>To highlight the technical issues, let us consider an MDP with <span class="math inline">\(T = 1\)</span>, i.e., a stochastic optimization problem. Define <span class="math display">\[
  V^*(s) = \inf_{a \in \ALPHABET A} c(s,a)
  \quad\text{and}\quad
  π^*(s) = \arg\inf_{a \in \ALPHABET A} c(s,a).
\]</span></p>
<p>We present a few examples below from <span class="citation" data-cites="Blackwell1965">Blackwell (<a href="../references.html#ref-Blackwell1965" role="doc-biblioref">1965</a>)</span> to highlight technical issues with non-finite state models.</p>
<div id="exm-Blackwell-no-optimal-policy" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.3 (No optimal policy)</strong></span> Let <span class="math inline">\(\ALPHABET S = \{s_\circ\}\)</span>, <span class="math inline">\(\ALPHABET A = \integers_{\ge 0}\)</span> Consider <span class="math inline">\(c(s_\circ,a) = (a+1)/a\)</span>. Here <span class="math inline">\(v^*(s_\circ) = 1\)</span> but there is no policy which achieves this cost.</p>
</div>
<p>In the above example, there is no optimal policy, but given any <span class="math inline">\(ε &gt; 0\)</span>, we can identify an <span class="math inline">\(ε\)</span>-optimal policy. The next example shows that we can have a much severe situation where the value function is not measurable. The example relies on the following fact:</p>
<blockquote class="blockquote">
<p>There exist Borel sets in <span class="math inline">\(\reals^2\)</span> whose projection on <span class="math inline">\(\reals\)</span> is not Borel. See <a href="https://en.wikipedia.org/wiki/Projection_(measure_theory)">:the wikipedia article on projections</a> for a discussion.</p>
</blockquote>
<div id="exm-Blackwell-non-measurable-value-function" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.4 (Non-measurable value function)</strong></span> Let <span class="math inline">\(\ALPHABET S = \ALPHABET A = [0,1]\)</span> and let <span class="math inline">\(B \subset \ALPHABET S × \ALPHABET A\)</span> such that <span class="math inline">\(B\)</span> is measurable but its projection on <span class="math inline">\(D\)</span> onto <span class="math inline">\(\ALPHABET S\)</span> is not. Consider <span class="math inline">\(c(s,a) = -\IND\{ (s,a) \in B \}\)</span>. Note that <span class="math display">\[
  v(s) = \inf_{a \in \ALPHABET A} c(s,a) =
  \inf_{a \in \ALPHABET A} -\IND\{ (s,a) \in B \} =
  -\IND\{s \in D \}
\]</span> which is not Borel measurable.</p>
</div>
<p>See <span class="citation" data-cites="Piunovskiy2011">Piunovskiy (<a href="../references.html#ref-Piunovskiy2011" role="doc-biblioref">2011</a>)</span> for various examples on what can go wrong in MDPs. In particular, Example 1.4.15 of <span class="citation" data-cites="Piunovskiy2011">Piunovskiy (<a href="../references.html#ref-Piunovskiy2011" role="doc-biblioref">2011</a>)</span> extends <a href="#exm-Blackwell-non-measurable-value-function" class="quarto-xref">Example&nbsp;<span>5.4</span></a> to provide an example where there is no <span class="math inline">\(ε\)</span>-optimal policy! (<span class="citation" data-cites="Blackwell1965">Blackwell (<a href="../references.html#ref-Blackwell1965" role="doc-biblioref">1965</a>)</span> also has such an example, but it is much harder to parse).</p>
<!-- See example 1.4.15 -->
<p>There are two ways to resolve the issue with non-existence of optimal policies: either assume that <span class="math inline">\(\ALPHABET A\)</span> is compact or that the function that we are minimizing is coercive, so that the <span class="math inline">\(\arg\inf\)</span> can be replaced by an <span class="math inline">\(\arg\min\)</span>. Or work with <span class="math inline">\(ε\)</span>-optimal policies.</p>
<p>Resolving the measurability issue is more complicated. There are various <strong>measurable selection theorems</strong> in the literature to identify sufficient conditions for measurability of the value function and optimal policy. See <span class="citation" data-cites="HernandezLerma1996">Hernández-Lerma and Lasserre (<a href="../references.html#ref-HernandezLerma1996" role="doc-biblioref">1996</a>)</span> and <span class="citation" data-cites="HernandezLerma1999">(<a href="../references.html#ref-HernandezLerma1999" role="doc-biblioref">1999</a>)</span> for an accessible treatment of continous state MDPs.</p>
</section>
<section id="exercises" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="exercises">Exercises</h2>
<div id="exr-monotonicity-in-time" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.1 (Monotonicity in time)</strong></span> Consider an MDP where the dynamics and per-step cost are time-homogeneous, i.e., the function <span class="math inline">\(f_t\)</span> and the per-step cost <span class="math inline">\(c_t\)</span> do not depend on <span class="math inline">\(t\)</span> (except, possibly at the terminal time <span class="math inline">\(t=T\)</span>). Suppose that <span class="math inline">\(V^*_{T-1}(s) \le V^*_T(s)\)</span> for all <span class="math inline">\(s \in \ALPHABET S\)</span>. Then, show that <span class="math display">\[ V^*_{t}(s) \le V^*_{t+1}(s), \quad
   \text{for all $s \in \ALPHABET S$ and $t$}.\]</span></p>
<p>Similarly, if we have that <span class="math inline">\(V^*_{T-1}(s) \ge V^*_T(s)\)</span> for all <span class="math inline">\(s \in
\ALPHABET S\)</span>, then <span class="math display">\[ V^*_{t}(s) \ge V^*_{t+1}(s), \quad
   \text{for all $s \in \ALPHABET S$ and $t$}.\]</span></p>
</div>
<div id="exr-maximizing-tail-probabilities" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.2 (Dynamic programming for maximizing tail probabilities)</strong></span> Consider a dynamical system that evolves as follows: <span class="math display">\[
  S_{t+1} = f_t(S_t, A_t, W_t)
\]</span> where <span class="math inline">\(\{S_1, W_1, \dots, W_T\}\)</span> are independent random variables and the control actions <span class="math inline">\(A_t\)</span> are chosen according to a history dependent policy <span class="math inline">\(π = (π_1, \dots, π_T)\)</span>: <span class="math display">\[
  A_t = π_t(S_{1:t}, A_{1:t-1}).
\]</span> Given a sequence of functions <span class="math inline">\(h_t \colon \ALPHABET S \mapsto \reals\)</span>, the cost of a policy <span class="math inline">\(π\)</span> is given by the probability that <span class="math inline">\(h_t(S_t)\)</span> exceeds a given threshold <span class="math inline">\(α \in \reals\)</span> at some time, i.e., <span class="math display">\[
  J(π) = \PR^{π}\left( \max_{0 \le t \le T} h_t(S_t) \ge α \right).
\]</span></p>
<p>Show that the above cost can be put in an additive form that would enable us to use the theory developed in the class to tackle this setup.</p>
</div>
<div id="exr-internet-of-things" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.3 (Optimal strategy in internet of things)</strong></span> Consider an IoT (Internet of Things) device which is observing an autoregressive process <span class="math inline">\(\{X_t\}_{t \ge 0}\)</span>, <span class="math inline">\(X_t \in \integers\)</span>, which starts at <span class="math inline">\(X_1 = 0\)</span> and for <span class="math inline">\(t &gt; 1\)</span> evolves as <span class="math display">\[ X_{t+1} = X_t + W_t \]</span> where <span class="math inline">\(\{W_t\}_{t \ge 1}\)</span> is an i.i.d. process with <span class="math inline">\(W_t \in \{ -5, \dots,
5 \}\)</span> with <span class="math display">\[ \PR(W_t = w) =
\begin{cases}
  \frac{1}{5} - \frac{|w|}{25}, &amp; \text{if } |w| \le 5 \\
  0, &amp; \text{otherwise}
\end{cases}\]</span></p>
<p>The IoT device can either transmit its observation (denoted by <span class="math inline">\(A_t = 1\)</span>) or not (denoted by <span class="math inline">\(A_t = 0\)</span>). Transmitting a packet has a cost <span class="math inline">\(\lambda\)</span> while not transmitting has no cost.</p>
<p>When <span class="math inline">\(A_t = 0\)</span>, the receiver estimates the state of the process as the previously transmitted observation <span class="math inline">\(Z_t\)</span> and incurs a cost <span class="math inline">\((X_t -
Z_t)^2\)</span>.</p>
<p>The above system can be modeled as an MDP with state <span class="math inline">\(\{S_t \}_{t \ge 0}\)</span>, where <span class="math inline">\(S_t = X_t - Z_t\)</span>. It can be shown that the dynamics of <span class="math inline">\(\{S_t\}_{t
\ge 1}\)</span> are as follows: <span class="math display">\[ S_{t+1} = \begin{cases}
    S_t + W_t, &amp; \text{if } A_t = 0 \\
    W_t, &amp; \text{if } A_t = 1
  \end{cases} \]</span></p>
<p>The per-step cost is given by <span class="math display">\[ c(s,a) = \lambda a + (1-a)s^2. \]</span></p>
<p>The objective of this exercise is to find the optimal policy for the above problem using dynamic programming.</p>
<p>In this model, the state space is unbounded which makes it difficult to use dynamic programming. So, we construct approximate dynamics as follows. We pick a large number <span class="math inline">\(B\)</span> and assume that the dynamics are: <span class="math display">\[ S_{t+1} = \begin{cases}
    [S_t + W_t]_{-B}^B, &amp; \text{if } A_t = 0 \\
    [W_t]_{-B}^B, &amp; \text{if } A_t = 1
  \end{cases} \]</span></p>
<p>So, we can effective consider the state space to be <span class="math inline">\(\{-B, \dots, B\}\)</span>.</p>
<ol type="a">
<li><p>Solve the dynamic program for <span class="math inline">\(T = 20\)</span>, <span class="math inline">\(λ = 100\)</span>, and <span class="math inline">\(B = 100\)</span>.</p></li>
<li><p>Plot the value function for <span class="math inline">\(t \in \{1, 5, 10, 19 \}\)</span> on the same plot.</p></li>
<li><p>Plot the optimal policy for <span class="math inline">\(t \in \{1, 5, 10, 19 \}\)</span>.</p></li>
<li><p>Change the value of <span class="math inline">\(B\)</span> in the set <span class="math inline">\(\{50, 60, 70, 80 \}\)</span> to make sure that our truncation does not have a significant impact on the value function and the optimal policy.</p></li>
</ol>
</div>
<div id="exr-machine-replacement" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.4</strong></span> Consider the model of <a href="#exm-machine-replacement" class="quarto-xref">Example&nbsp;<span>5.2</span></a> where <span class="math inline">\(W \sim \text{Binon}(n,p)\)</span>.</p>
<ol type="a">
<li><p>Solve the dynamic program for <span class="math inline">\(T=20\)</span>, <span class="math inline">\(n=10\)</span>, <span class="math inline">\(p=0.4\)</span>, <span class="math inline">\(h(s) = 2s\)</span>, and <span class="math inline">\(λ=10\)</span>.</p></li>
<li><p>Plot the value function for <span class="math inline">\(t \in \{1, 5, 10, 19 \}\)</span> on the same plot.</p></li>
<li><p>Plot the optimal policy for <span class="math inline">\(t \in \{1, 5, 10, 19 \}\)</span>.</p></li>
<li><p>Based on these results, guess the structure of the optimal policy. Change the values of the parameters to check if the structure is retained. We will learn how to establish that such a structure is optimal in <a href="monotone-mdps.html#exr-monotone-machine-replacement" class="quarto-xref">Exercise&nbsp;<span>8.5</span></a>.</p></li>
</ol>
</div>
</section>
<section id="notes" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="notes">Notes</h2>
<p>The proof idea for the optimality of Markov policies is based on a proof by <span class="citation" data-cites="Witsenhausen1979">Witsenhausen (<a href="../references.html#ref-Witsenhausen1979" role="doc-biblioref">1979</a>)</span> on the structure of optimal coding policies for real-time communication. Note that the proof does not require us to find a dynamic programming decomposition of the problem. This is in contrast with the standard textbook proof where the optimality of Markov policies is proved as part of the dynamic programming decomposition.</p>
<p><a href="#exr-internet-of-things" class="quarto-xref">Exercise&nbsp;<span>5.3</span></a> is adapted from <span class="citation" data-cites="Chakravorty2018">Chakravorty and Mahajan (<a href="../references.html#ref-Chakravorty2018" role="doc-biblioref">2018</a>)</span>.</p>
<!-- FIXME
Add notes on the history of MDPs. Zormello's proof of existence of value of chess. Results on inventory management. Bellman's book. Howard's book (Howard's paper on history of MDP). Bellman's anecdote on the term "dynamic programming".
-->


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-Blackwell1964" class="csl-entry" role="listitem">
<span class="smallcaps">Blackwell, D.</span> 1964. Memoryless strategies in finite-stage dynamic programming. <em>The Annals of Mathematical Statistics</em> <em>35</em>, 2, 863–865. DOI: <a href="https://doi.org/10.1214/aoms/1177703586">10.1214/aoms/1177703586</a>.
</div>
<div id="ref-Blackwell1965" class="csl-entry" role="listitem">
<span class="smallcaps">Blackwell, D.</span> 1965. Discounted dynamic programming. <em>The Annals of Mathematical Statistics</em> <em>36</em>, 1, 226–235. DOI: <a href="https://doi.org/10.1214/aoms/1177700285">10.1214/aoms/1177700285</a>.
</div>
<div id="ref-Chakravorty2018" class="csl-entry" role="listitem">
<span class="smallcaps">Chakravorty, J. and Mahajan, A.</span> 2018. Sufficient conditions for the value function and optimal strategy to be even and quasi-convex. <em>IEEE Transactions on Automatic Control</em> <em>63</em>, 11, 3858–3864. DOI: <a href="https://doi.org/10.1109/TAC.2018.2800796">10.1109/TAC.2018.2800796</a>.
</div>
<div id="ref-HernandezLerma1996" class="csl-entry" role="listitem">
<span class="smallcaps">Hernández-Lerma, O. and Lasserre, J.B.</span> 1996. <em>Discrete-time markov control processes</em>. Springer New York. DOI: <a href="https://doi.org/10.1007/978-1-4612-0729-0">10.1007/978-1-4612-0729-0</a>.
</div>
<div id="ref-HernandezLerma1999" class="csl-entry" role="listitem">
<span class="smallcaps">Hernández-Lerma, O. and Lasserre, J.B.</span> 1999. <em>Further topics on discrete-time markov control processes</em>. Springer New York. DOI: <a href="https://doi.org/10.1007/978-1-4612-0561-6">10.1007/978-1-4612-0561-6</a>.
</div>
<div id="ref-Piunovskiy2011" class="csl-entry" role="listitem">
<span class="smallcaps">Piunovskiy, A.B.</span> 2011. <em>Examples in markov decision processes</em>. Imperial College Proess. DOI: <a href="https://doi.org/10.1142/p809">10.1142/p809</a>.
</div>
<div id="ref-Shwartz2001" class="csl-entry" role="listitem">
<span class="smallcaps">Shwartz, A.</span> 2001. Death and discounting. <em><span>IEEE</span> Transactions on Automatic Control</em> <em>46</em>, 4, 644–647. DOI: <a href="https://doi.org/10.1109/9.917668">10.1109/9.917668</a>.
</div>
<div id="ref-Witsenhausen1979" class="csl-entry" role="listitem">
<span class="smallcaps">Witsenhausen, H.S.</span> 1979. On the structure of real-time source coders. <em>Bell System Technical Journal</em> <em>58</em>, 6, 1437–1451.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../stochastic-optimization/interchange.html" class="pagination-link  aria-label=" &lt;span="" arguments&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Interchange arguments</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../mdps/gambling.html" class="pagination-link" aria-label="<span class='chapter-number'>6</span>&nbsp; <span class='chapter-title'>Optimal gambling</span>">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Optimal gambling</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/adityam/stochastic-control/edit/quarto/mdps/intro.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer><script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>